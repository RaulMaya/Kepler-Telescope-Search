{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7d7bfd5",
   "metadata": {},
   "source": [
    "## Logistic Regression Model for Kepler Space Telescope Data\n",
    "The purpose of this project is to reinforce my data science and machine learning knowledge, and to help others in their journeys. I'm not an expert on these topics, and I'm conscious that there are a lot of tools, concepts and techniques that I need to master. That's why I develop this project, to share with the community the tools, concepts and techniques, that I have learned across my data science journey. I'm open to comments, critics and feedback that would help me to develop learn best practices and corrections in case I was wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8295fb",
   "metadata": {},
   "source": [
    "#### About Logistic Regression\n",
    "- It is a classification model.\n",
    "- Mostly used to predict a discrete set of categories, such as Yes/No, Young/Old, Cold/Hot, etc.\n",
    "- They are stronger with linear relationships.\n",
    "- They work only with numbers (All your data need to be numerical).\n",
    "- By default, logistic regression cannot be used for classification tasks that have more than two targets.\n",
    "- Since we have more than 2 classes to predict, we are going to use multinomial multi_class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f557db0",
   "metadata": {},
   "source": [
    "### Importing basic modules for data extraction and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ac03516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import warnings\n",
    "#warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7df663d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>...</td>\n",
       "      <td>-81</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.490000e-05</td>\n",
       "      <td>-1.490000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>-176</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>-174</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.760000e-06</td>\n",
       "      <td>-3.760000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>-211</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>1.050000e-05</td>\n",
       "      <td>-1.050000e-05</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>...</td>\n",
       "      <td>-232</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n",
       "0       CONFIRMED              0              0              0              0   \n",
       "1  FALSE POSITIVE              0              1              0              0   \n",
       "2  FALSE POSITIVE              0              1              0              0   \n",
       "3       CONFIRMED              0              0              0              0   \n",
       "4       CONFIRMED              0              0              0              0   \n",
       "\n",
       "   koi_period  koi_period_err1  koi_period_err2  koi_time0bk  \\\n",
       "0   54.418383     2.479000e-04    -2.479000e-04   162.513840   \n",
       "1   19.899140     1.490000e-05    -1.490000e-05   175.850252   \n",
       "2    1.736952     2.630000e-07    -2.630000e-07   170.307565   \n",
       "3    2.525592     3.760000e-06    -3.760000e-06   171.595550   \n",
       "4    4.134435     1.050000e-05    -1.050000e-05   172.979370   \n",
       "\n",
       "   koi_time0bk_err1  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "0          0.003520  ...             -81      4.467           0.064   \n",
       "1          0.000581  ...            -176      4.544           0.044   \n",
       "2          0.000115  ...            -174      4.564           0.053   \n",
       "3          0.001130  ...            -211      4.438           0.070   \n",
       "4          0.001900  ...            -232      4.486           0.054   \n",
       "\n",
       "   koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
       "0          -0.096     0.927          0.105         -0.061  291.93423   \n",
       "1          -0.176     0.868          0.233         -0.078  297.00482   \n",
       "2          -0.168     0.791          0.201         -0.067  285.53461   \n",
       "3          -0.210     1.046          0.334         -0.133  288.75488   \n",
       "4          -0.229     0.972          0.315         -0.105  296.28613   \n",
       "\n",
       "         dec  koi_kepmag  \n",
       "0  48.141651      15.347  \n",
       "1  48.134129      15.436  \n",
       "2  48.285210      15.597  \n",
       "3  48.226200      15.509  \n",
       "4  48.224670      15.714  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kepler_df = pd.read_csv('../../data/exoplanet_data.csv')\n",
    "kepler_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d93a6541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6991 entries, 0 to 6990\n",
      "Data columns (total 41 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   koi_disposition    6991 non-null   object \n",
      " 1   koi_fpflag_nt      6991 non-null   int64  \n",
      " 2   koi_fpflag_ss      6991 non-null   int64  \n",
      " 3   koi_fpflag_co      6991 non-null   int64  \n",
      " 4   koi_fpflag_ec      6991 non-null   int64  \n",
      " 5   koi_period         6991 non-null   float64\n",
      " 6   koi_period_err1    6991 non-null   float64\n",
      " 7   koi_period_err2    6991 non-null   float64\n",
      " 8   koi_time0bk        6991 non-null   float64\n",
      " 9   koi_time0bk_err1   6991 non-null   float64\n",
      " 10  koi_time0bk_err2   6991 non-null   float64\n",
      " 11  koi_impact         6991 non-null   float64\n",
      " 12  koi_impact_err1    6991 non-null   float64\n",
      " 13  koi_impact_err2    6991 non-null   float64\n",
      " 14  koi_duration       6991 non-null   float64\n",
      " 15  koi_duration_err1  6991 non-null   float64\n",
      " 16  koi_duration_err2  6991 non-null   float64\n",
      " 17  koi_depth          6991 non-null   float64\n",
      " 18  koi_depth_err1     6991 non-null   float64\n",
      " 19  koi_depth_err2     6991 non-null   float64\n",
      " 20  koi_prad           6991 non-null   float64\n",
      " 21  koi_prad_err1      6991 non-null   float64\n",
      " 22  koi_prad_err2      6991 non-null   float64\n",
      " 23  koi_teq            6991 non-null   int64  \n",
      " 24  koi_insol          6991 non-null   float64\n",
      " 25  koi_insol_err1     6991 non-null   float64\n",
      " 26  koi_insol_err2     6991 non-null   float64\n",
      " 27  koi_model_snr      6991 non-null   float64\n",
      " 28  koi_tce_plnt_num   6991 non-null   int64  \n",
      " 29  koi_steff          6991 non-null   int64  \n",
      " 30  koi_steff_err1     6991 non-null   int64  \n",
      " 31  koi_steff_err2     6991 non-null   int64  \n",
      " 32  koi_slogg          6991 non-null   float64\n",
      " 33  koi_slogg_err1     6991 non-null   float64\n",
      " 34  koi_slogg_err2     6991 non-null   float64\n",
      " 35  koi_srad           6991 non-null   float64\n",
      " 36  koi_srad_err1      6991 non-null   float64\n",
      " 37  koi_srad_err2      6991 non-null   float64\n",
      " 38  ra                 6991 non-null   float64\n",
      " 39  dec                6991 non-null   float64\n",
      " 40  koi_kepmag         6991 non-null   float64\n",
      "dtypes: float64(31), int64(9), object(1)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "kepler_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46a4c0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe has a length of 41 columns.\n",
      "There are 3 outcomes/predictions/targets: {'CANDIDATE', 'CONFIRMED', 'FALSE POSITIVE'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"The dataframe has a length of {len(kepler_df.columns)} columns.\")\n",
    "print(f\"There are 3 outcomes/predictions/targets: {set(kepler_df['koi_disposition'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4c0948",
   "metadata": {},
   "source": [
    "#### Replacing categorical target values with numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed6c7e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kepler_df['koi_disposition'] = kepler_df['koi_disposition'].replace({'CONFIRMED': 0, 'FALSE POSITIVE': 1, 'CANDIDATE': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d69991",
   "metadata": {},
   "source": [
    "### Taking a look to the relationship between features and target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2635447",
   "metadata": {},
   "source": [
    "#### Relationship between the target which is 'koi_disposition' and all the features available in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fa977eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "koi_disposition      1.000000\n",
       "koi_fpflag_nt        0.000416\n",
       "koi_fpflag_ss        0.013503\n",
       "koi_fpflag_co        0.008531\n",
       "koi_fpflag_ec        0.008041\n",
       "koi_period           0.124647\n",
       "koi_period_err1      0.099048\n",
       "koi_period_err2     -0.099048\n",
       "koi_time0bk          0.070445\n",
       "koi_time0bk_err1     0.147719\n",
       "koi_time0bk_err2    -0.147719\n",
       "koi_impact           0.010607\n",
       "koi_impact_err1      0.058572\n",
       "koi_impact_err2     -0.013980\n",
       "koi_duration         0.029554\n",
       "koi_duration_err1    0.156587\n",
       "koi_duration_err2   -0.156587\n",
       "koi_depth            0.008694\n",
       "koi_depth_err1       0.001797\n",
       "koi_depth_err2      -0.001797\n",
       "koi_prad             0.001485\n",
       "koi_prad_err1        0.003135\n",
       "koi_prad_err2       -0.000998\n",
       "koi_teq              0.021275\n",
       "koi_insol            0.012070\n",
       "koi_insol_err1       0.014604\n",
       "koi_insol_err2      -0.014159\n",
       "koi_model_snr       -0.016351\n",
       "koi_tce_plnt_num    -0.095550\n",
       "koi_steff            0.071048\n",
       "koi_steff_err1       0.173227\n",
       "koi_steff_err2      -0.148902\n",
       "koi_slogg           -0.071437\n",
       "koi_slogg_err1       0.068356\n",
       "koi_slogg_err2      -0.165136\n",
       "koi_srad             0.035999\n",
       "koi_srad_err1        0.069335\n",
       "koi_srad_err2       -0.036944\n",
       "ra                   0.063848\n",
       "dec                 -0.045244\n",
       "koi_kepmag           0.004264\n",
       "Name: koi_disposition, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation = kepler_df.corr()\n",
    "correlation['koi_disposition']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4307f08",
   "metadata": {},
   "source": [
    "### Plotting heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c77ae5",
   "metadata": {},
   "source": [
    "#### Two ways of creating a heatmap with Plotly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f364e9d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorscale": [
          [
           0,
           "#000000"
          ],
          [
           0.0625,
           "#001f4d"
          ],
          [
           0.125,
           "#003786"
          ],
          [
           0.1875,
           "#0e58a8"
          ],
          [
           0.25,
           "#217eb8"
          ],
          [
           0.3125,
           "#30a4ca"
          ],
          [
           0.375,
           "#54c8df"
          ],
          [
           0.4375,
           "#9be4ef"
          ],
          [
           0.5,
           "#e1e9d1"
          ],
          [
           0.5625,
           "#f3d573"
          ],
          [
           0.625,
           "#e7b000"
          ],
          [
           0.6875,
           "#da8200"
          ],
          [
           0.75,
           "#c65400"
          ],
          [
           0.8125,
           "#ac2301"
          ],
          [
           0.875,
           "#820000"
          ],
          [
           0.9375,
           "#4c0000"
          ],
          [
           1,
           "#000000"
          ]
         ],
         "text": [
          [
           1,
           0.0004,
           0.0135,
           0.0085,
           0.008,
           0.1246,
           0.099,
           -0.099,
           0.0704,
           0.1477,
           -0.1477
          ],
          [
           0.0004,
           1,
           -0.2411,
           0.0031,
           0.0508,
           0.4087,
           0.3532,
           -0.3532,
           0.2494,
           0.2507,
           -0.2507
          ],
          [
           0.0135,
           -0.2411,
           1,
           0.1445,
           0.1017,
           -0.156,
           -0.1342,
           0.1342,
           -0.1115,
           -0.177,
           0.177
          ],
          [
           0.0085,
           0.0031,
           0.1445,
           1,
           0.5383,
           -0.1648,
           -0.0844,
           0.0844,
           -0.1215,
           -0.0231,
           0.0231
          ],
          [
           0.008,
           0.0508,
           0.1017,
           0.5383,
           1,
           -0.1389,
           -0.0799,
           0.0799,
           -0.0998,
           0.0136,
           -0.0136
          ],
          [
           0.1246,
           0.4087,
           -0.156,
           -0.1648,
           -0.1389,
           1,
           0.6748,
           -0.6748,
           0.6552,
           0.2725,
           -0.2725
          ],
          [
           0.099,
           0.3532,
           -0.1342,
           -0.0844,
           -0.0799,
           0.6748,
           1,
           -1,
           0.4696,
           0.472,
           -0.472
          ],
          [
           -0.099,
           -0.3532,
           0.1342,
           0.0844,
           0.0799,
           -0.6748,
           -1,
           1,
           -0.4696,
           -0.472,
           0.472
          ],
          [
           0.0704,
           0.2494,
           -0.1115,
           -0.1215,
           -0.0998,
           0.6552,
           0.4696,
           -0.4696,
           1,
           0.1628,
           -0.1628
          ],
          [
           0.1477,
           0.2507,
           -0.177,
           -0.0231,
           0.0136,
           0.2725,
           0.472,
           -0.472,
           0.1628,
           1,
           -1
          ],
          [
           -0.1477,
           -0.2507,
           0.177,
           0.0231,
           -0.0136,
           -0.2725,
           -0.472,
           0.472,
           -0.1628,
           -1,
           1
          ]
         ],
         "textfont": {
          "size": 12
         },
         "texttemplate": "%{text}",
         "type": "heatmap",
         "x": [
          "koi_disposition",
          "koi_fpflag_nt",
          "koi_fpflag_ss",
          "koi_fpflag_co",
          "koi_fpflag_ec",
          "koi_period",
          "koi_period_err1",
          "koi_period_err2",
          "koi_time0bk",
          "koi_time0bk_err1",
          "koi_time0bk_err2"
         ],
         "y": [
          "koi_disposition",
          "koi_fpflag_nt",
          "koi_fpflag_ss",
          "koi_fpflag_co",
          "koi_fpflag_ec",
          "koi_period",
          "koi_period_err1",
          "koi_period_err2",
          "koi_time0bk",
          "koi_time0bk_err1",
          "koi_time0bk_err2"
         ],
         "z": [
          [
           1,
           0,
           0.014,
           0.009,
           0.008,
           0.125,
           0.099,
           -0.099,
           0.07,
           0.148,
           -0.148
          ],
          [
           0,
           1,
           -0.241,
           0.003,
           0.051,
           0.409,
           0.353,
           -0.353,
           0.249,
           0.251,
           -0.251
          ],
          [
           0.014,
           -0.241,
           1,
           0.145,
           0.102,
           -0.156,
           -0.134,
           0.134,
           -0.111,
           -0.177,
           0.177
          ],
          [
           0.009,
           0.003,
           0.145,
           1,
           0.538,
           -0.165,
           -0.084,
           0.084,
           -0.121,
           -0.023,
           0.023
          ],
          [
           0.008,
           0.051,
           0.102,
           0.538,
           1,
           -0.139,
           -0.08,
           0.08,
           -0.1,
           0.014,
           -0.014
          ],
          [
           0.125,
           0.409,
           -0.156,
           -0.165,
           -0.139,
           1,
           0.675,
           -0.675,
           0.655,
           0.273,
           -0.273
          ],
          [
           0.099,
           0.353,
           -0.134,
           -0.084,
           -0.08,
           0.675,
           1,
           -1,
           0.47,
           0.472,
           -0.472
          ],
          [
           -0.099,
           -0.353,
           0.134,
           0.084,
           0.08,
           -0.675,
           -1,
           1,
           -0.47,
           -0.472,
           0.472
          ],
          [
           0.07,
           0.249,
           -0.111,
           -0.121,
           -0.1,
           0.655,
           0.47,
           -0.47,
           1,
           0.163,
           -0.163
          ],
          [
           0.148,
           0.251,
           -0.177,
           -0.023,
           0.014,
           0.273,
           0.472,
           -0.472,
           0.163,
           1,
           -1
          ],
          [
           -0.148,
           -0.251,
           0.177,
           0.023,
           -0.014,
           -0.273,
           -0.472,
           0.472,
           -0.163,
           -1,
           1
          ]
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "First 10 Features Heatmap Correlation with the Target",
         "x": 0.5
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"7838b20c-3cfb-422e-9b30-2f482fb76d77\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7838b20c-3cfb-422e-9b30-2f482fb76d77\")) {                    Plotly.newPlot(                        \"7838b20c-3cfb-422e-9b30-2f482fb76d77\",                        [{\"colorscale\":[[0.0,\"#000000\"],[0.0625,\"#001f4d\"],[0.125,\"#003786\"],[0.1875,\"#0e58a8\"],[0.25,\"#217eb8\"],[0.3125,\"#30a4ca\"],[0.375,\"#54c8df\"],[0.4375,\"#9be4ef\"],[0.5,\"#e1e9d1\"],[0.5625,\"#f3d573\"],[0.625,\"#e7b000\"],[0.6875,\"#da8200\"],[0.75,\"#c65400\"],[0.8125,\"#ac2301\"],[0.875,\"#820000\"],[0.9375,\"#4c0000\"],[1.0,\"#000000\"]],\"text\":[[1.0,0.0004,0.0135,0.0085,0.008,0.1246,0.099,-0.099,0.0704,0.1477,-0.1477],[0.0004,1.0,-0.2411,0.0031,0.0508,0.4087,0.3532,-0.3532,0.2494,0.2507,-0.2507],[0.0135,-0.2411,1.0,0.1445,0.1017,-0.156,-0.1342,0.1342,-0.1115,-0.177,0.177],[0.0085,0.0031,0.1445,1.0,0.5383,-0.1648,-0.0844,0.0844,-0.1215,-0.0231,0.0231],[0.008,0.0508,0.1017,0.5383,1.0,-0.1389,-0.0799,0.0799,-0.0998,0.0136,-0.0136],[0.1246,0.4087,-0.156,-0.1648,-0.1389,1.0,0.6748,-0.6748,0.6552,0.2725,-0.2725],[0.099,0.3532,-0.1342,-0.0844,-0.0799,0.6748,1.0,-1.0,0.4696,0.472,-0.472],[-0.099,-0.3532,0.1342,0.0844,0.0799,-0.6748,-1.0,1.0,-0.4696,-0.472,0.472],[0.0704,0.2494,-0.1115,-0.1215,-0.0998,0.6552,0.4696,-0.4696,1.0,0.1628,-0.1628],[0.1477,0.2507,-0.177,-0.0231,0.0136,0.2725,0.472,-0.472,0.1628,1.0,-1.0],[-0.1477,-0.2507,0.177,0.0231,-0.0136,-0.2725,-0.472,0.472,-0.1628,-1.0,1.0]],\"textfont\":{\"size\":12},\"texttemplate\":\"%{text}\",\"x\":[\"koi_disposition\",\"koi_fpflag_nt\",\"koi_fpflag_ss\",\"koi_fpflag_co\",\"koi_fpflag_ec\",\"koi_period\",\"koi_period_err1\",\"koi_period_err2\",\"koi_time0bk\",\"koi_time0bk_err1\",\"koi_time0bk_err2\"],\"y\":[\"koi_disposition\",\"koi_fpflag_nt\",\"koi_fpflag_ss\",\"koi_fpflag_co\",\"koi_fpflag_ec\",\"koi_period\",\"koi_period_err1\",\"koi_period_err2\",\"koi_time0bk\",\"koi_time0bk_err1\",\"koi_time0bk_err2\"],\"z\":[[1.0,0.0,0.014,0.009,0.008,0.125,0.099,-0.099,0.07,0.148,-0.148],[0.0,1.0,-0.241,0.003,0.051,0.409,0.353,-0.353,0.249,0.251,-0.251],[0.014,-0.241,1.0,0.145,0.102,-0.156,-0.134,0.134,-0.111,-0.177,0.177],[0.009,0.003,0.145,1.0,0.538,-0.165,-0.084,0.084,-0.121,-0.023,0.023],[0.008,0.051,0.102,0.538,1.0,-0.139,-0.08,0.08,-0.1,0.014,-0.014],[0.125,0.409,-0.156,-0.165,-0.139,1.0,0.675,-0.675,0.655,0.273,-0.273],[0.099,0.353,-0.134,-0.084,-0.08,0.675,1.0,-1.0,0.47,0.472,-0.472],[-0.099,-0.353,0.134,0.084,0.08,-0.675,-1.0,1.0,-0.47,-0.472,0.472],[0.07,0.249,-0.111,-0.121,-0.1,0.655,0.47,-0.47,1.0,0.163,-0.163],[0.148,0.251,-0.177,-0.023,0.014,0.273,0.472,-0.472,0.163,1.0,-1.0],[-0.148,-0.251,0.177,0.023,-0.014,-0.273,-0.472,0.472,-0.163,-1.0,1.0]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"First 10 Features Heatmap Correlation with the Target\",\"x\":0.5}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('7838b20c-3cfb-422e-9b30-2f482fb76d77');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'logistic_regression_complete_heatmap.html'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as figfac\n",
    "from plotly.offline import offline, iplot\n",
    "\n",
    "fig = go.Figure(data=go.Heatmap(z = correlation.iloc[:11, :11].round(3).values.tolist(),\n",
    "                                x=correlation.iloc[:11, :11].columns.to_list(),\n",
    "                                y = correlation.iloc[:11, :11].index.to_list(),\n",
    "                                colorscale= 'icefire',\n",
    "                                text=correlation.iloc[:11, :11].round(4).values,\n",
    "                                texttemplate=\"%{text}\",\n",
    "                                textfont={\"size\":12}))\n",
    "\n",
    "fig.update_layout(title_text='First 10 Features Heatmap Correlation with the Target', title_x=0.5)\n",
    "\n",
    "fig.show()\n",
    "fig.write_image(\"logistic_regression_complete_heatmap.png\")\n",
    "offline.plot(fig, filename='logistic_regression_complete_heatmap.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15eaf70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "colorscale": [
          [
           0,
           "rgb(0,0,255)"
          ],
          [
           1,
           "rgb(255,0,0)"
          ]
         ],
         "reversescale": false,
         "showscale": false,
         "type": "heatmap",
         "x": [
          "koi_disposition",
          "koi_fpflag_nt",
          "koi_fpflag_ss",
          "koi_fpflag_co",
          "koi_fpflag_ec",
          "koi_period",
          "koi_period_err1",
          "koi_period_err2",
          "koi_time0bk",
          "koi_time0bk_err1",
          "koi_time0bk_err2"
         ],
         "y": [
          "koi_disposition",
          "koi_fpflag_nt",
          "koi_fpflag_ss",
          "koi_fpflag_co",
          "koi_fpflag_ec",
          "koi_period",
          "koi_period_err1",
          "koi_period_err2",
          "koi_time0bk",
          "koi_time0bk_err1",
          "koi_time0bk_err2"
         ],
         "z": [
          [
           1,
           0,
           0.014,
           0.009,
           0.008,
           0.125,
           0.099,
           -0.099,
           0.07,
           0.148,
           -0.148
          ],
          [
           0,
           1,
           -0.241,
           0.003,
           0.051,
           0.409,
           0.353,
           -0.353,
           0.249,
           0.251,
           -0.251
          ],
          [
           0.014,
           -0.241,
           1,
           0.145,
           0.102,
           -0.156,
           -0.134,
           0.134,
           -0.111,
           -0.177,
           0.177
          ],
          [
           0.009,
           0.003,
           0.145,
           1,
           0.538,
           -0.165,
           -0.084,
           0.084,
           -0.121,
           -0.023,
           0.023
          ],
          [
           0.008,
           0.051,
           0.102,
           0.538,
           1,
           -0.139,
           -0.08,
           0.08,
           -0.1,
           0.014,
           -0.014
          ],
          [
           0.125,
           0.409,
           -0.156,
           -0.165,
           -0.139,
           1,
           0.675,
           -0.675,
           0.655,
           0.273,
           -0.273
          ],
          [
           0.099,
           0.353,
           -0.134,
           -0.084,
           -0.08,
           0.675,
           1,
           -1,
           0.47,
           0.472,
           -0.472
          ],
          [
           -0.099,
           -0.353,
           0.134,
           0.084,
           0.08,
           -0.675,
           -1,
           1,
           -0.47,
           -0.472,
           0.472
          ],
          [
           0.07,
           0.249,
           -0.111,
           -0.121,
           -0.1,
           0.655,
           0.47,
           -0.47,
           1,
           0.163,
           -0.163
          ],
          [
           0.148,
           0.251,
           -0.177,
           -0.023,
           0.014,
           0.273,
           0.472,
           -0.472,
           0.163,
           1,
           -1
          ],
          [
           -0.148,
           -0.251,
           0.177,
           0.023,
           -0.014,
           -0.273,
           -0.472,
           0.472,
           -0.163,
           -1,
           1
          ]
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "1.0",
          "x": "koi_disposition",
          "xref": "x",
          "y": "koi_disposition",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0004",
          "x": "koi_fpflag_nt",
          "xref": "x",
          "y": "koi_disposition",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0135",
          "x": "koi_fpflag_ss",
          "xref": "x",
          "y": "koi_disposition",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0085",
          "x": "koi_fpflag_co",
          "xref": "x",
          "y": "koi_disposition",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.008",
          "x": "koi_fpflag_ec",
          "xref": "x",
          "y": "koi_disposition",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.1246",
          "x": "koi_period",
          "xref": "x",
          "y": "koi_disposition",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.099",
          "x": "koi_period_err1",
          "xref": "x",
          "y": "koi_disposition",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.099",
          "x": "koi_period_err2",
          "xref": "x",
          "y": "koi_disposition",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0704",
          "x": "koi_time0bk",
          "xref": "x",
          "y": "koi_disposition",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.1477",
          "x": "koi_time0bk_err1",
          "xref": "x",
          "y": "koi_disposition",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.1477",
          "x": "koi_time0bk_err2",
          "xref": "x",
          "y": "koi_disposition",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0004",
          "x": "koi_disposition",
          "xref": "x",
          "y": "koi_fpflag_nt",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "1.0",
          "x": "koi_fpflag_nt",
          "xref": "x",
          "y": "koi_fpflag_nt",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.2411",
          "x": "koi_fpflag_ss",
          "xref": "x",
          "y": "koi_fpflag_nt",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0031",
          "x": "koi_fpflag_co",
          "xref": "x",
          "y": "koi_fpflag_nt",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0508",
          "x": "koi_fpflag_ec",
          "xref": "x",
          "y": "koi_fpflag_nt",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.4087",
          "x": "koi_period",
          "xref": "x",
          "y": "koi_fpflag_nt",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.3532",
          "x": "koi_period_err1",
          "xref": "x",
          "y": "koi_fpflag_nt",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.3532",
          "x": "koi_period_err2",
          "xref": "x",
          "y": "koi_fpflag_nt",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.2494",
          "x": "koi_time0bk",
          "xref": "x",
          "y": "koi_fpflag_nt",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.2507",
          "x": "koi_time0bk_err1",
          "xref": "x",
          "y": "koi_fpflag_nt",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.2507",
          "x": "koi_time0bk_err2",
          "xref": "x",
          "y": "koi_fpflag_nt",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0135",
          "x": "koi_disposition",
          "xref": "x",
          "y": "koi_fpflag_ss",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.2411",
          "x": "koi_fpflag_nt",
          "xref": "x",
          "y": "koi_fpflag_ss",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "1.0",
          "x": "koi_fpflag_ss",
          "xref": "x",
          "y": "koi_fpflag_ss",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.1445",
          "x": "koi_fpflag_co",
          "xref": "x",
          "y": "koi_fpflag_ss",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.1017",
          "x": "koi_fpflag_ec",
          "xref": "x",
          "y": "koi_fpflag_ss",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.156",
          "x": "koi_period",
          "xref": "x",
          "y": "koi_fpflag_ss",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.1342",
          "x": "koi_period_err1",
          "xref": "x",
          "y": "koi_fpflag_ss",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.1342",
          "x": "koi_period_err2",
          "xref": "x",
          "y": "koi_fpflag_ss",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.1115",
          "x": "koi_time0bk",
          "xref": "x",
          "y": "koi_fpflag_ss",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.177",
          "x": "koi_time0bk_err1",
          "xref": "x",
          "y": "koi_fpflag_ss",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.177",
          "x": "koi_time0bk_err2",
          "xref": "x",
          "y": "koi_fpflag_ss",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0085",
          "x": "koi_disposition",
          "xref": "x",
          "y": "koi_fpflag_co",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0031",
          "x": "koi_fpflag_nt",
          "xref": "x",
          "y": "koi_fpflag_co",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.1445",
          "x": "koi_fpflag_ss",
          "xref": "x",
          "y": "koi_fpflag_co",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "1.0",
          "x": "koi_fpflag_co",
          "xref": "x",
          "y": "koi_fpflag_co",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.5383",
          "x": "koi_fpflag_ec",
          "xref": "x",
          "y": "koi_fpflag_co",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.1648",
          "x": "koi_period",
          "xref": "x",
          "y": "koi_fpflag_co",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.0844",
          "x": "koi_period_err1",
          "xref": "x",
          "y": "koi_fpflag_co",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0844",
          "x": "koi_period_err2",
          "xref": "x",
          "y": "koi_fpflag_co",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.1215",
          "x": "koi_time0bk",
          "xref": "x",
          "y": "koi_fpflag_co",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.0231",
          "x": "koi_time0bk_err1",
          "xref": "x",
          "y": "koi_fpflag_co",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0231",
          "x": "koi_time0bk_err2",
          "xref": "x",
          "y": "koi_fpflag_co",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.008",
          "x": "koi_disposition",
          "xref": "x",
          "y": "koi_fpflag_ec",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0508",
          "x": "koi_fpflag_nt",
          "xref": "x",
          "y": "koi_fpflag_ec",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.1017",
          "x": "koi_fpflag_ss",
          "xref": "x",
          "y": "koi_fpflag_ec",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.5383",
          "x": "koi_fpflag_co",
          "xref": "x",
          "y": "koi_fpflag_ec",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "1.0",
          "x": "koi_fpflag_ec",
          "xref": "x",
          "y": "koi_fpflag_ec",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.1389",
          "x": "koi_period",
          "xref": "x",
          "y": "koi_fpflag_ec",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.0799",
          "x": "koi_period_err1",
          "xref": "x",
          "y": "koi_fpflag_ec",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0799",
          "x": "koi_period_err2",
          "xref": "x",
          "y": "koi_fpflag_ec",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.0998",
          "x": "koi_time0bk",
          "xref": "x",
          "y": "koi_fpflag_ec",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0136",
          "x": "koi_time0bk_err1",
          "xref": "x",
          "y": "koi_fpflag_ec",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.0136",
          "x": "koi_time0bk_err2",
          "xref": "x",
          "y": "koi_fpflag_ec",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.1246",
          "x": "koi_disposition",
          "xref": "x",
          "y": "koi_period",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.4087",
          "x": "koi_fpflag_nt",
          "xref": "x",
          "y": "koi_period",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.156",
          "x": "koi_fpflag_ss",
          "xref": "x",
          "y": "koi_period",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.1648",
          "x": "koi_fpflag_co",
          "xref": "x",
          "y": "koi_period",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.1389",
          "x": "koi_fpflag_ec",
          "xref": "x",
          "y": "koi_period",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "1.0",
          "x": "koi_period",
          "xref": "x",
          "y": "koi_period",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.6748",
          "x": "koi_period_err1",
          "xref": "x",
          "y": "koi_period",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.6748",
          "x": "koi_period_err2",
          "xref": "x",
          "y": "koi_period",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.6552",
          "x": "koi_time0bk",
          "xref": "x",
          "y": "koi_period",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.2725",
          "x": "koi_time0bk_err1",
          "xref": "x",
          "y": "koi_period",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.2725",
          "x": "koi_time0bk_err2",
          "xref": "x",
          "y": "koi_period",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.099",
          "x": "koi_disposition",
          "xref": "x",
          "y": "koi_period_err1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.3532",
          "x": "koi_fpflag_nt",
          "xref": "x",
          "y": "koi_period_err1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.1342",
          "x": "koi_fpflag_ss",
          "xref": "x",
          "y": "koi_period_err1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.0844",
          "x": "koi_fpflag_co",
          "xref": "x",
          "y": "koi_period_err1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.0799",
          "x": "koi_fpflag_ec",
          "xref": "x",
          "y": "koi_period_err1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.6748",
          "x": "koi_period",
          "xref": "x",
          "y": "koi_period_err1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "1.0",
          "x": "koi_period_err1",
          "xref": "x",
          "y": "koi_period_err1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-1.0",
          "x": "koi_period_err2",
          "xref": "x",
          "y": "koi_period_err1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.4696",
          "x": "koi_time0bk",
          "xref": "x",
          "y": "koi_period_err1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.472",
          "x": "koi_time0bk_err1",
          "xref": "x",
          "y": "koi_period_err1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.472",
          "x": "koi_time0bk_err2",
          "xref": "x",
          "y": "koi_period_err1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.099",
          "x": "koi_disposition",
          "xref": "x",
          "y": "koi_period_err2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.3532",
          "x": "koi_fpflag_nt",
          "xref": "x",
          "y": "koi_period_err2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.1342",
          "x": "koi_fpflag_ss",
          "xref": "x",
          "y": "koi_period_err2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0844",
          "x": "koi_fpflag_co",
          "xref": "x",
          "y": "koi_period_err2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0799",
          "x": "koi_fpflag_ec",
          "xref": "x",
          "y": "koi_period_err2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.6748",
          "x": "koi_period",
          "xref": "x",
          "y": "koi_period_err2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-1.0",
          "x": "koi_period_err1",
          "xref": "x",
          "y": "koi_period_err2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "1.0",
          "x": "koi_period_err2",
          "xref": "x",
          "y": "koi_period_err2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.4696",
          "x": "koi_time0bk",
          "xref": "x",
          "y": "koi_period_err2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.472",
          "x": "koi_time0bk_err1",
          "xref": "x",
          "y": "koi_period_err2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.472",
          "x": "koi_time0bk_err2",
          "xref": "x",
          "y": "koi_period_err2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0704",
          "x": "koi_disposition",
          "xref": "x",
          "y": "koi_time0bk",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.2494",
          "x": "koi_fpflag_nt",
          "xref": "x",
          "y": "koi_time0bk",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.1115",
          "x": "koi_fpflag_ss",
          "xref": "x",
          "y": "koi_time0bk",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.1215",
          "x": "koi_fpflag_co",
          "xref": "x",
          "y": "koi_time0bk",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.0998",
          "x": "koi_fpflag_ec",
          "xref": "x",
          "y": "koi_time0bk",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.6552",
          "x": "koi_period",
          "xref": "x",
          "y": "koi_time0bk",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.4696",
          "x": "koi_period_err1",
          "xref": "x",
          "y": "koi_time0bk",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.4696",
          "x": "koi_period_err2",
          "xref": "x",
          "y": "koi_time0bk",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "1.0",
          "x": "koi_time0bk",
          "xref": "x",
          "y": "koi_time0bk",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.1628",
          "x": "koi_time0bk_err1",
          "xref": "x",
          "y": "koi_time0bk",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.1628",
          "x": "koi_time0bk_err2",
          "xref": "x",
          "y": "koi_time0bk",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.1477",
          "x": "koi_disposition",
          "xref": "x",
          "y": "koi_time0bk_err1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.2507",
          "x": "koi_fpflag_nt",
          "xref": "x",
          "y": "koi_time0bk_err1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.177",
          "x": "koi_fpflag_ss",
          "xref": "x",
          "y": "koi_time0bk_err1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.0231",
          "x": "koi_fpflag_co",
          "xref": "x",
          "y": "koi_time0bk_err1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0136",
          "x": "koi_fpflag_ec",
          "xref": "x",
          "y": "koi_time0bk_err1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.2725",
          "x": "koi_period",
          "xref": "x",
          "y": "koi_time0bk_err1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.472",
          "x": "koi_period_err1",
          "xref": "x",
          "y": "koi_time0bk_err1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.472",
          "x": "koi_period_err2",
          "xref": "x",
          "y": "koi_time0bk_err1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.1628",
          "x": "koi_time0bk",
          "xref": "x",
          "y": "koi_time0bk_err1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "1.0",
          "x": "koi_time0bk_err1",
          "xref": "x",
          "y": "koi_time0bk_err1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-1.0",
          "x": "koi_time0bk_err2",
          "xref": "x",
          "y": "koi_time0bk_err1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.1477",
          "x": "koi_disposition",
          "xref": "x",
          "y": "koi_time0bk_err2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.2507",
          "x": "koi_fpflag_nt",
          "xref": "x",
          "y": "koi_time0bk_err2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.177",
          "x": "koi_fpflag_ss",
          "xref": "x",
          "y": "koi_time0bk_err2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.0231",
          "x": "koi_fpflag_co",
          "xref": "x",
          "y": "koi_time0bk_err2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.0136",
          "x": "koi_fpflag_ec",
          "xref": "x",
          "y": "koi_time0bk_err2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.2725",
          "x": "koi_period",
          "xref": "x",
          "y": "koi_time0bk_err2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.472",
          "x": "koi_period_err1",
          "xref": "x",
          "y": "koi_time0bk_err2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0.472",
          "x": "koi_period_err2",
          "xref": "x",
          "y": "koi_time0bk_err2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-0.1628",
          "x": "koi_time0bk",
          "xref": "x",
          "y": "koi_time0bk_err2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "-1.0",
          "x": "koi_time0bk_err1",
          "xref": "x",
          "y": "koi_time0bk_err2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "1.0",
          "x": "koi_time0bk_err2",
          "xref": "x",
          "y": "koi_time0bk_err2",
          "yref": "y"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "dtick": 1,
         "gridcolor": "rgb(0, 0, 0)",
         "side": "top",
         "ticks": ""
        },
        "yaxis": {
         "dtick": 1,
         "ticks": "",
         "ticksuffix": "  "
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"c54301d9-b365-41ea-9409-cf78d03395b1\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c54301d9-b365-41ea-9409-cf78d03395b1\")) {                    Plotly.newPlot(                        \"c54301d9-b365-41ea-9409-cf78d03395b1\",                        [{\"colorscale\":[[0.0,\"rgb(0,0,255)\"],[1.0,\"rgb(255,0,0)\"]],\"reversescale\":false,\"showscale\":false,\"x\":[\"koi_disposition\",\"koi_fpflag_nt\",\"koi_fpflag_ss\",\"koi_fpflag_co\",\"koi_fpflag_ec\",\"koi_period\",\"koi_period_err1\",\"koi_period_err2\",\"koi_time0bk\",\"koi_time0bk_err1\",\"koi_time0bk_err2\"],\"y\":[\"koi_disposition\",\"koi_fpflag_nt\",\"koi_fpflag_ss\",\"koi_fpflag_co\",\"koi_fpflag_ec\",\"koi_period\",\"koi_period_err1\",\"koi_period_err2\",\"koi_time0bk\",\"koi_time0bk_err1\",\"koi_time0bk_err2\"],\"z\":[[1.0,0.0,0.014,0.009,0.008,0.125,0.099,-0.099,0.07,0.148,-0.148],[0.0,1.0,-0.241,0.003,0.051,0.409,0.353,-0.353,0.249,0.251,-0.251],[0.014,-0.241,1.0,0.145,0.102,-0.156,-0.134,0.134,-0.111,-0.177,0.177],[0.009,0.003,0.145,1.0,0.538,-0.165,-0.084,0.084,-0.121,-0.023,0.023],[0.008,0.051,0.102,0.538,1.0,-0.139,-0.08,0.08,-0.1,0.014,-0.014],[0.125,0.409,-0.156,-0.165,-0.139,1.0,0.675,-0.675,0.655,0.273,-0.273],[0.099,0.353,-0.134,-0.084,-0.08,0.675,1.0,-1.0,0.47,0.472,-0.472],[-0.099,-0.353,0.134,0.084,0.08,-0.675,-1.0,1.0,-0.47,-0.472,0.472],[0.07,0.249,-0.111,-0.121,-0.1,0.655,0.47,-0.47,1.0,0.163,-0.163],[0.148,0.251,-0.177,-0.023,0.014,0.273,0.472,-0.472,0.163,1.0,-1.0],[-0.148,-0.251,0.177,0.023,-0.014,-0.273,-0.472,0.472,-0.163,-1.0,1.0]],\"type\":\"heatmap\"}],                        {\"annotations\":[{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"1.0\",\"x\":\"koi_disposition\",\"xref\":\"x\",\"y\":\"koi_disposition\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.0004\",\"x\":\"koi_fpflag_nt\",\"xref\":\"x\",\"y\":\"koi_disposition\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.0135\",\"x\":\"koi_fpflag_ss\",\"xref\":\"x\",\"y\":\"koi_disposition\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.0085\",\"x\":\"koi_fpflag_co\",\"xref\":\"x\",\"y\":\"koi_disposition\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.008\",\"x\":\"koi_fpflag_ec\",\"xref\":\"x\",\"y\":\"koi_disposition\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.1246\",\"x\":\"koi_period\",\"xref\":\"x\",\"y\":\"koi_disposition\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.099\",\"x\":\"koi_period_err1\",\"xref\":\"x\",\"y\":\"koi_disposition\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.099\",\"x\":\"koi_period_err2\",\"xref\":\"x\",\"y\":\"koi_disposition\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.0704\",\"x\":\"koi_time0bk\",\"xref\":\"x\",\"y\":\"koi_disposition\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.1477\",\"x\":\"koi_time0bk_err1\",\"xref\":\"x\",\"y\":\"koi_disposition\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.1477\",\"x\":\"koi_time0bk_err2\",\"xref\":\"x\",\"y\":\"koi_disposition\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.0004\",\"x\":\"koi_disposition\",\"xref\":\"x\",\"y\":\"koi_fpflag_nt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"1.0\",\"x\":\"koi_fpflag_nt\",\"xref\":\"x\",\"y\":\"koi_fpflag_nt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.2411\",\"x\":\"koi_fpflag_ss\",\"xref\":\"x\",\"y\":\"koi_fpflag_nt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.0031\",\"x\":\"koi_fpflag_co\",\"xref\":\"x\",\"y\":\"koi_fpflag_nt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.0508\",\"x\":\"koi_fpflag_ec\",\"xref\":\"x\",\"y\":\"koi_fpflag_nt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.4087\",\"x\":\"koi_period\",\"xref\":\"x\",\"y\":\"koi_fpflag_nt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.3532\",\"x\":\"koi_period_err1\",\"xref\":\"x\",\"y\":\"koi_fpflag_nt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.3532\",\"x\":\"koi_period_err2\",\"xref\":\"x\",\"y\":\"koi_fpflag_nt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.2494\",\"x\":\"koi_time0bk\",\"xref\":\"x\",\"y\":\"koi_fpflag_nt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.2507\",\"x\":\"koi_time0bk_err1\",\"xref\":\"x\",\"y\":\"koi_fpflag_nt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.2507\",\"x\":\"koi_time0bk_err2\",\"xref\":\"x\",\"y\":\"koi_fpflag_nt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.0135\",\"x\":\"koi_disposition\",\"xref\":\"x\",\"y\":\"koi_fpflag_ss\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.2411\",\"x\":\"koi_fpflag_nt\",\"xref\":\"x\",\"y\":\"koi_fpflag_ss\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"1.0\",\"x\":\"koi_fpflag_ss\",\"xref\":\"x\",\"y\":\"koi_fpflag_ss\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.1445\",\"x\":\"koi_fpflag_co\",\"xref\":\"x\",\"y\":\"koi_fpflag_ss\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.1017\",\"x\":\"koi_fpflag_ec\",\"xref\":\"x\",\"y\":\"koi_fpflag_ss\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.156\",\"x\":\"koi_period\",\"xref\":\"x\",\"y\":\"koi_fpflag_ss\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.1342\",\"x\":\"koi_period_err1\",\"xref\":\"x\",\"y\":\"koi_fpflag_ss\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.1342\",\"x\":\"koi_period_err2\",\"xref\":\"x\",\"y\":\"koi_fpflag_ss\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.1115\",\"x\":\"koi_time0bk\",\"xref\":\"x\",\"y\":\"koi_fpflag_ss\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.177\",\"x\":\"koi_time0bk_err1\",\"xref\":\"x\",\"y\":\"koi_fpflag_ss\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.177\",\"x\":\"koi_time0bk_err2\",\"xref\":\"x\",\"y\":\"koi_fpflag_ss\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.0085\",\"x\":\"koi_disposition\",\"xref\":\"x\",\"y\":\"koi_fpflag_co\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.0031\",\"x\":\"koi_fpflag_nt\",\"xref\":\"x\",\"y\":\"koi_fpflag_co\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.1445\",\"x\":\"koi_fpflag_ss\",\"xref\":\"x\",\"y\":\"koi_fpflag_co\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"1.0\",\"x\":\"koi_fpflag_co\",\"xref\":\"x\",\"y\":\"koi_fpflag_co\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.5383\",\"x\":\"koi_fpflag_ec\",\"xref\":\"x\",\"y\":\"koi_fpflag_co\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.1648\",\"x\":\"koi_period\",\"xref\":\"x\",\"y\":\"koi_fpflag_co\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.0844\",\"x\":\"koi_period_err1\",\"xref\":\"x\",\"y\":\"koi_fpflag_co\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.0844\",\"x\":\"koi_period_err2\",\"xref\":\"x\",\"y\":\"koi_fpflag_co\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.1215\",\"x\":\"koi_time0bk\",\"xref\":\"x\",\"y\":\"koi_fpflag_co\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.0231\",\"x\":\"koi_time0bk_err1\",\"xref\":\"x\",\"y\":\"koi_fpflag_co\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.0231\",\"x\":\"koi_time0bk_err2\",\"xref\":\"x\",\"y\":\"koi_fpflag_co\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.008\",\"x\":\"koi_disposition\",\"xref\":\"x\",\"y\":\"koi_fpflag_ec\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.0508\",\"x\":\"koi_fpflag_nt\",\"xref\":\"x\",\"y\":\"koi_fpflag_ec\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.1017\",\"x\":\"koi_fpflag_ss\",\"xref\":\"x\",\"y\":\"koi_fpflag_ec\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.5383\",\"x\":\"koi_fpflag_co\",\"xref\":\"x\",\"y\":\"koi_fpflag_ec\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"1.0\",\"x\":\"koi_fpflag_ec\",\"xref\":\"x\",\"y\":\"koi_fpflag_ec\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.1389\",\"x\":\"koi_period\",\"xref\":\"x\",\"y\":\"koi_fpflag_ec\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.0799\",\"x\":\"koi_period_err1\",\"xref\":\"x\",\"y\":\"koi_fpflag_ec\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.0799\",\"x\":\"koi_period_err2\",\"xref\":\"x\",\"y\":\"koi_fpflag_ec\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.0998\",\"x\":\"koi_time0bk\",\"xref\":\"x\",\"y\":\"koi_fpflag_ec\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.0136\",\"x\":\"koi_time0bk_err1\",\"xref\":\"x\",\"y\":\"koi_fpflag_ec\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.0136\",\"x\":\"koi_time0bk_err2\",\"xref\":\"x\",\"y\":\"koi_fpflag_ec\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.1246\",\"x\":\"koi_disposition\",\"xref\":\"x\",\"y\":\"koi_period\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.4087\",\"x\":\"koi_fpflag_nt\",\"xref\":\"x\",\"y\":\"koi_period\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.156\",\"x\":\"koi_fpflag_ss\",\"xref\":\"x\",\"y\":\"koi_period\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.1648\",\"x\":\"koi_fpflag_co\",\"xref\":\"x\",\"y\":\"koi_period\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.1389\",\"x\":\"koi_fpflag_ec\",\"xref\":\"x\",\"y\":\"koi_period\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"1.0\",\"x\":\"koi_period\",\"xref\":\"x\",\"y\":\"koi_period\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.6748\",\"x\":\"koi_period_err1\",\"xref\":\"x\",\"y\":\"koi_period\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.6748\",\"x\":\"koi_period_err2\",\"xref\":\"x\",\"y\":\"koi_period\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.6552\",\"x\":\"koi_time0bk\",\"xref\":\"x\",\"y\":\"koi_period\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.2725\",\"x\":\"koi_time0bk_err1\",\"xref\":\"x\",\"y\":\"koi_period\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.2725\",\"x\":\"koi_time0bk_err2\",\"xref\":\"x\",\"y\":\"koi_period\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.099\",\"x\":\"koi_disposition\",\"xref\":\"x\",\"y\":\"koi_period_err1\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.3532\",\"x\":\"koi_fpflag_nt\",\"xref\":\"x\",\"y\":\"koi_period_err1\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.1342\",\"x\":\"koi_fpflag_ss\",\"xref\":\"x\",\"y\":\"koi_period_err1\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.0844\",\"x\":\"koi_fpflag_co\",\"xref\":\"x\",\"y\":\"koi_period_err1\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.0799\",\"x\":\"koi_fpflag_ec\",\"xref\":\"x\",\"y\":\"koi_period_err1\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.6748\",\"x\":\"koi_period\",\"xref\":\"x\",\"y\":\"koi_period_err1\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"1.0\",\"x\":\"koi_period_err1\",\"xref\":\"x\",\"y\":\"koi_period_err1\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-1.0\",\"x\":\"koi_period_err2\",\"xref\":\"x\",\"y\":\"koi_period_err1\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.4696\",\"x\":\"koi_time0bk\",\"xref\":\"x\",\"y\":\"koi_period_err1\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.472\",\"x\":\"koi_time0bk_err1\",\"xref\":\"x\",\"y\":\"koi_period_err1\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.472\",\"x\":\"koi_time0bk_err2\",\"xref\":\"x\",\"y\":\"koi_period_err1\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.099\",\"x\":\"koi_disposition\",\"xref\":\"x\",\"y\":\"koi_period_err2\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.3532\",\"x\":\"koi_fpflag_nt\",\"xref\":\"x\",\"y\":\"koi_period_err2\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.1342\",\"x\":\"koi_fpflag_ss\",\"xref\":\"x\",\"y\":\"koi_period_err2\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.0844\",\"x\":\"koi_fpflag_co\",\"xref\":\"x\",\"y\":\"koi_period_err2\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.0799\",\"x\":\"koi_fpflag_ec\",\"xref\":\"x\",\"y\":\"koi_period_err2\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.6748\",\"x\":\"koi_period\",\"xref\":\"x\",\"y\":\"koi_period_err2\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-1.0\",\"x\":\"koi_period_err1\",\"xref\":\"x\",\"y\":\"koi_period_err2\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"1.0\",\"x\":\"koi_period_err2\",\"xref\":\"x\",\"y\":\"koi_period_err2\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.4696\",\"x\":\"koi_time0bk\",\"xref\":\"x\",\"y\":\"koi_period_err2\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.472\",\"x\":\"koi_time0bk_err1\",\"xref\":\"x\",\"y\":\"koi_period_err2\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.472\",\"x\":\"koi_time0bk_err2\",\"xref\":\"x\",\"y\":\"koi_period_err2\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.0704\",\"x\":\"koi_disposition\",\"xref\":\"x\",\"y\":\"koi_time0bk\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.2494\",\"x\":\"koi_fpflag_nt\",\"xref\":\"x\",\"y\":\"koi_time0bk\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.1115\",\"x\":\"koi_fpflag_ss\",\"xref\":\"x\",\"y\":\"koi_time0bk\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.1215\",\"x\":\"koi_fpflag_co\",\"xref\":\"x\",\"y\":\"koi_time0bk\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.0998\",\"x\":\"koi_fpflag_ec\",\"xref\":\"x\",\"y\":\"koi_time0bk\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.6552\",\"x\":\"koi_period\",\"xref\":\"x\",\"y\":\"koi_time0bk\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.4696\",\"x\":\"koi_period_err1\",\"xref\":\"x\",\"y\":\"koi_time0bk\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.4696\",\"x\":\"koi_period_err2\",\"xref\":\"x\",\"y\":\"koi_time0bk\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"1.0\",\"x\":\"koi_time0bk\",\"xref\":\"x\",\"y\":\"koi_time0bk\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.1628\",\"x\":\"koi_time0bk_err1\",\"xref\":\"x\",\"y\":\"koi_time0bk\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.1628\",\"x\":\"koi_time0bk_err2\",\"xref\":\"x\",\"y\":\"koi_time0bk\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.1477\",\"x\":\"koi_disposition\",\"xref\":\"x\",\"y\":\"koi_time0bk_err1\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.2507\",\"x\":\"koi_fpflag_nt\",\"xref\":\"x\",\"y\":\"koi_time0bk_err1\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.177\",\"x\":\"koi_fpflag_ss\",\"xref\":\"x\",\"y\":\"koi_time0bk_err1\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.0231\",\"x\":\"koi_fpflag_co\",\"xref\":\"x\",\"y\":\"koi_time0bk_err1\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.0136\",\"x\":\"koi_fpflag_ec\",\"xref\":\"x\",\"y\":\"koi_time0bk_err1\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.2725\",\"x\":\"koi_period\",\"xref\":\"x\",\"y\":\"koi_time0bk_err1\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.472\",\"x\":\"koi_period_err1\",\"xref\":\"x\",\"y\":\"koi_time0bk_err1\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.472\",\"x\":\"koi_period_err2\",\"xref\":\"x\",\"y\":\"koi_time0bk_err1\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.1628\",\"x\":\"koi_time0bk\",\"xref\":\"x\",\"y\":\"koi_time0bk_err1\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"1.0\",\"x\":\"koi_time0bk_err1\",\"xref\":\"x\",\"y\":\"koi_time0bk_err1\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-1.0\",\"x\":\"koi_time0bk_err2\",\"xref\":\"x\",\"y\":\"koi_time0bk_err1\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.1477\",\"x\":\"koi_disposition\",\"xref\":\"x\",\"y\":\"koi_time0bk_err2\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.2507\",\"x\":\"koi_fpflag_nt\",\"xref\":\"x\",\"y\":\"koi_time0bk_err2\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.177\",\"x\":\"koi_fpflag_ss\",\"xref\":\"x\",\"y\":\"koi_time0bk_err2\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.0231\",\"x\":\"koi_fpflag_co\",\"xref\":\"x\",\"y\":\"koi_time0bk_err2\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.0136\",\"x\":\"koi_fpflag_ec\",\"xref\":\"x\",\"y\":\"koi_time0bk_err2\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.2725\",\"x\":\"koi_period\",\"xref\":\"x\",\"y\":\"koi_time0bk_err2\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.472\",\"x\":\"koi_period_err1\",\"xref\":\"x\",\"y\":\"koi_time0bk_err2\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"0.472\",\"x\":\"koi_period_err2\",\"xref\":\"x\",\"y\":\"koi_time0bk_err2\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-0.1628\",\"x\":\"koi_time0bk\",\"xref\":\"x\",\"y\":\"koi_time0bk_err2\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"-1.0\",\"x\":\"koi_time0bk_err1\",\"xref\":\"x\",\"y\":\"koi_time0bk_err2\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"1.0\",\"x\":\"koi_time0bk_err2\",\"xref\":\"x\",\"y\":\"koi_time0bk_err2\",\"yref\":\"y\"}],\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"dtick\":1,\"gridcolor\":\"rgb(0, 0, 0)\",\"side\":\"top\",\"ticks\":\"\"},\"yaxis\":{\"dtick\":1,\"ticks\":\"\",\"ticksuffix\":\"  \"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('c54301d9-b365-41ea-9409-cf78d03395b1');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iplot(figfac.create_annotated_heatmap(correlation.iloc[:11, :11].round(3).values, x=correlation.iloc[:11, :11].columns.to_list(), \n",
    "                                  y=correlation.iloc[:11, :11].index.to_list(), annotation_text=correlation.iloc[:11, :11].round(4).values, colorscale= 'bluered'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79053c80",
   "metadata": {},
   "source": [
    "### Setting target and features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f9434b",
   "metadata": {},
   "source": [
    "#### Splitting up my target columns from the rest of my features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a582134",
   "metadata": {},
   "source": [
    "In the following cell, it will be set the target (y) and the features (X), in this case for the target, the selected column will be 'koi_disposition', meanwhile for the features variable, the rest of the columns will be selected by droping the 'koi_disposition' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "65a8e6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6991, 40)\n",
      "(6991,)\n"
     ]
    }
   ],
   "source": [
    "features = kepler_df.drop('koi_disposition', axis = 1)\n",
    "target = kepler_df['koi_disposition']\n",
    "\n",
    "print(features.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bff5b4b",
   "metadata": {},
   "source": [
    "### Initiating the Logistic Regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b23c29",
   "metadata": {},
   "source": [
    "Importing LogisticRegression and creating a LogisticRegression with a parameter of max iterations of 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0f346531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(max_iter=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a75e5ee",
   "metadata": {},
   "source": [
    "#### Import the train_test_split, and split the target and features into train and test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d25a98",
   "metadata": {},
   "source": [
    "The parameters used in this project were:\n",
    "- features (X)\n",
    "- target (y)\n",
    "- test_size: it represents the proportion of the actual data, that will be considered as test; it should be between 0 and 1, and the default value is 0.25, in this case the test size is 0.30.\n",
    "- random_state: it is a parameter that helps you get the same results, for instance, suppose you want to get a random number between 1 and 1000, and you get 50. It is very unlikely that in your next run, you get 50 again, that's what the 'random_state' is basically for; by setting the same 'random_state' on both runs, you will get the same number of times you run the same parameter for 'random_state'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e2f0f736",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96415800",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bb64f1",
   "metadata": {},
   "source": [
    "#### Scaling our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "12407995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d026e60",
   "metadata": {},
   "source": [
    "#### Fitting the LogisticRegression model with the scaled X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5a2083bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b464a5",
   "metadata": {},
   "source": [
    "#### Selecting the features with RFE (Recursive Feature Elimination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bd7ebe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "rfe = RFE(logreg, n_features_to_select=10, step=1)\n",
    "features_selected = rfe.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7ae9cffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>koi_time0bk_err2</th>\n",
       "      <th>koi_duration_err1</th>\n",
       "      <th>koi_duration_err2</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_steff_err1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>-0.003520</td>\n",
       "      <td>0.11600</td>\n",
       "      <td>-0.11600</td>\n",
       "      <td>25.8</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>-0.000581</td>\n",
       "      <td>0.03410</td>\n",
       "      <td>-0.03410</td>\n",
       "      <td>76.3</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>0.00537</td>\n",
       "      <td>-0.00537</td>\n",
       "      <td>505.6</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>-0.001130</td>\n",
       "      <td>0.04200</td>\n",
       "      <td>-0.04200</td>\n",
       "      <td>40.9</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>-0.001900</td>\n",
       "      <td>0.06730</td>\n",
       "      <td>-0.06730</td>\n",
       "      <td>40.2</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n",
       "0              0              0              0              0   \n",
       "1              0              1              0              0   \n",
       "2              0              1              0              0   \n",
       "3              0              0              0              0   \n",
       "4              0              0              0              0   \n",
       "\n",
       "   koi_time0bk_err1  koi_time0bk_err2  koi_duration_err1  koi_duration_err2  \\\n",
       "0          0.003520         -0.003520            0.11600           -0.11600   \n",
       "1          0.000581         -0.000581            0.03410           -0.03410   \n",
       "2          0.000115         -0.000115            0.00537           -0.00537   \n",
       "3          0.001130         -0.001130            0.04200           -0.04200   \n",
       "4          0.001900         -0.001900            0.06730           -0.06730   \n",
       "\n",
       "   koi_model_snr  koi_steff_err1  \n",
       "0           25.8              81  \n",
       "1           76.3             158  \n",
       "2          505.6             157  \n",
       "3           40.9             169  \n",
       "4           40.2             189  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_features = features.loc[:,features_selected.support_]\n",
    "relevant_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5bca1897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>koi_time0bk_err2</th>\n",
       "      <th>koi_duration_err1</th>\n",
       "      <th>koi_duration_err2</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_steff_err1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>-0.003520</td>\n",
       "      <td>0.11600</td>\n",
       "      <td>-0.11600</td>\n",
       "      <td>25.8</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>-0.000581</td>\n",
       "      <td>0.03410</td>\n",
       "      <td>-0.03410</td>\n",
       "      <td>76.3</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>0.00537</td>\n",
       "      <td>-0.00537</td>\n",
       "      <td>505.6</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>-0.001130</td>\n",
       "      <td>0.04200</td>\n",
       "      <td>-0.04200</td>\n",
       "      <td>40.9</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>-0.001900</td>\n",
       "      <td>0.06730</td>\n",
       "      <td>-0.06730</td>\n",
       "      <td>40.2</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  \\\n",
       "0                0              0              0              0   \n",
       "1                1              0              1              0   \n",
       "2                1              0              1              0   \n",
       "3                0              0              0              0   \n",
       "4                0              0              0              0   \n",
       "\n",
       "   koi_fpflag_ec  koi_time0bk_err1  koi_time0bk_err2  koi_duration_err1  \\\n",
       "0              0          0.003520         -0.003520            0.11600   \n",
       "1              0          0.000581         -0.000581            0.03410   \n",
       "2              0          0.000115         -0.000115            0.00537   \n",
       "3              0          0.001130         -0.001130            0.04200   \n",
       "4              0          0.001900         -0.001900            0.06730   \n",
       "\n",
       "   koi_duration_err2  koi_model_snr  koi_steff_err1  \n",
       "0           -0.11600           25.8              81  \n",
       "1           -0.03410           76.3             158  \n",
       "2           -0.00537          505.6             157  \n",
       "3           -0.04200           40.9             169  \n",
       "4           -0.06730           40.2             189  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_corr_df = pd.merge(target, relevant_features, left_index=True, right_index=True)\n",
    "relevant_corr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b02598ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6991 entries, 0 to 6990\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   koi_disposition    6991 non-null   int64  \n",
      " 1   koi_fpflag_nt      6991 non-null   int64  \n",
      " 2   koi_fpflag_ss      6991 non-null   int64  \n",
      " 3   koi_fpflag_co      6991 non-null   int64  \n",
      " 4   koi_fpflag_ec      6991 non-null   int64  \n",
      " 5   koi_time0bk_err1   6991 non-null   float64\n",
      " 6   koi_time0bk_err2   6991 non-null   float64\n",
      " 7   koi_duration_err1  6991 non-null   float64\n",
      " 8   koi_duration_err2  6991 non-null   float64\n",
      " 9   koi_model_snr      6991 non-null   float64\n",
      " 10  koi_steff_err1     6991 non-null   int64  \n",
      "dtypes: float64(5), int64(6)\n",
      "memory usage: 600.9 KB\n"
     ]
    }
   ],
   "source": [
    "relevant_corr_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26b0f62",
   "metadata": {},
   "source": [
    "### Taking a look to the relationship between the top 10 most relevant features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d90feaa4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "koi_disposition      1.000000\n",
       "koi_fpflag_nt        0.000416\n",
       "koi_fpflag_ss        0.013503\n",
       "koi_fpflag_co        0.008531\n",
       "koi_fpflag_ec        0.008041\n",
       "koi_time0bk_err1     0.147719\n",
       "koi_time0bk_err2    -0.147719\n",
       "koi_duration_err1    0.156587\n",
       "koi_duration_err2   -0.156587\n",
       "koi_model_snr       -0.016351\n",
       "koi_steff_err1       0.173227\n",
       "Name: koi_disposition, dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_correlation = relevant_corr_df.corr()\n",
    "rel_correlation['koi_disposition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "06ad6357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorscale": [
          [
           0,
           "rgb(255,255,217)"
          ],
          [
           0.125,
           "rgb(237,248,177)"
          ],
          [
           0.25,
           "rgb(199,233,180)"
          ],
          [
           0.375,
           "rgb(127,205,187)"
          ],
          [
           0.5,
           "rgb(65,182,196)"
          ],
          [
           0.625,
           "rgb(29,145,192)"
          ],
          [
           0.75,
           "rgb(34,94,168)"
          ],
          [
           0.875,
           "rgb(37,52,148)"
          ],
          [
           1,
           "rgb(8,29,88)"
          ]
         ],
         "text": [
          [
           1,
           0.0004,
           0.0135,
           0.0085,
           0.008,
           0.1477,
           -0.1477,
           0.1566,
           -0.1566,
           -0.0164,
           0.1732
          ],
          [
           0.0004,
           1,
           -0.2411,
           0.0031,
           0.0508,
           0.2507,
           -0.2507,
           0.3376,
           -0.3376,
           -0.0792,
           0.1294
          ],
          [
           0.0135,
           -0.2411,
           1,
           0.1445,
           0.1017,
           -0.177,
           0.177,
           -0.1817,
           0.1817,
           0.4398,
           0.2223
          ],
          [
           0.0085,
           0.0031,
           0.1445,
           1,
           0.5383,
           -0.0231,
           0.0231,
           -0.005,
           0.005,
           -0.1345,
           0.1598
          ],
          [
           0.008,
           0.0508,
           0.1017,
           0.5383,
           1,
           0.0136,
           -0.0136,
           0.0254,
           -0.0254,
           -0.0919,
           0.1201
          ],
          [
           0.1477,
           0.2507,
           -0.177,
           -0.0231,
           0.0136,
           1,
           -1,
           0.5191,
           -0.5191,
           -0.132,
           0.0638
          ],
          [
           -0.1477,
           -0.2507,
           0.177,
           0.0231,
           -0.0136,
           -1,
           1,
           -0.5191,
           0.5191,
           0.132,
           -0.0638
          ],
          [
           0.1566,
           0.3376,
           -0.1817,
           -0.005,
           0.0254,
           0.5191,
           -0.5191,
           1,
           -1,
           -0.146,
           0.0766
          ],
          [
           -0.1566,
           -0.3376,
           0.1817,
           0.005,
           -0.0254,
           -0.5191,
           0.5191,
           -1,
           1,
           0.146,
           -0.0766
          ],
          [
           -0.0164,
           -0.0792,
           0.4398,
           -0.1345,
           -0.0919,
           -0.132,
           0.132,
           -0.146,
           0.146,
           1,
           0.1215
          ],
          [
           0.1732,
           0.1294,
           0.2223,
           0.1598,
           0.1201,
           0.0638,
           -0.0638,
           0.0766,
           -0.0766,
           0.1215,
           1
          ]
         ],
         "textfont": {
          "size": 12
         },
         "texttemplate": "%{text}",
         "type": "heatmap",
         "x": [
          "koi_disposition",
          "koi_fpflag_nt",
          "koi_fpflag_ss",
          "koi_fpflag_co",
          "koi_fpflag_ec",
          "koi_time0bk_err1",
          "koi_time0bk_err2",
          "koi_duration_err1",
          "koi_duration_err2",
          "koi_model_snr",
          "koi_steff_err1"
         ],
         "y": [
          "koi_disposition",
          "koi_fpflag_nt",
          "koi_fpflag_ss",
          "koi_fpflag_co",
          "koi_fpflag_ec",
          "koi_time0bk_err1",
          "koi_time0bk_err2",
          "koi_duration_err1",
          "koi_duration_err2",
          "koi_model_snr",
          "koi_steff_err1"
         ],
         "z": [
          [
           1,
           0,
           0.014,
           0.009,
           0.008,
           0.148,
           -0.148,
           0.157,
           -0.157,
           -0.016,
           0.173
          ],
          [
           0,
           1,
           -0.241,
           0.003,
           0.051,
           0.251,
           -0.251,
           0.338,
           -0.338,
           -0.079,
           0.129
          ],
          [
           0.014,
           -0.241,
           1,
           0.145,
           0.102,
           -0.177,
           0.177,
           -0.182,
           0.182,
           0.44,
           0.222
          ],
          [
           0.009,
           0.003,
           0.145,
           1,
           0.538,
           -0.023,
           0.023,
           -0.005,
           0.005,
           -0.134,
           0.16
          ],
          [
           0.008,
           0.051,
           0.102,
           0.538,
           1,
           0.014,
           -0.014,
           0.025,
           -0.025,
           -0.092,
           0.12
          ],
          [
           0.148,
           0.251,
           -0.177,
           -0.023,
           0.014,
           1,
           -1,
           0.519,
           -0.519,
           -0.132,
           0.064
          ],
          [
           -0.148,
           -0.251,
           0.177,
           0.023,
           -0.014,
           -1,
           1,
           -0.519,
           0.519,
           0.132,
           -0.064
          ],
          [
           0.157,
           0.338,
           -0.182,
           -0.005,
           0.025,
           0.519,
           -0.519,
           1,
           -1,
           -0.146,
           0.077
          ],
          [
           -0.157,
           -0.338,
           0.182,
           0.005,
           -0.025,
           -0.519,
           0.519,
           -1,
           1,
           0.146,
           -0.077
          ],
          [
           -0.016,
           -0.079,
           0.44,
           -0.134,
           -0.092,
           -0.132,
           0.132,
           -0.146,
           0.146,
           1,
           0.121
          ],
          [
           0.173,
           0.129,
           0.222,
           0.16,
           0.12,
           0.064,
           -0.064,
           0.077,
           -0.077,
           0.121,
           1
          ]
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Top 10 Most Relevant Features Heatmap Correlation with the Target",
         "x": 0.5
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"2ab79df0-adf3-4aa6-9dbd-4714f93e4573\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2ab79df0-adf3-4aa6-9dbd-4714f93e4573\")) {                    Plotly.newPlot(                        \"2ab79df0-adf3-4aa6-9dbd-4714f93e4573\",                        [{\"colorscale\":[[0.0,\"rgb(255,255,217)\"],[0.125,\"rgb(237,248,177)\"],[0.25,\"rgb(199,233,180)\"],[0.375,\"rgb(127,205,187)\"],[0.5,\"rgb(65,182,196)\"],[0.625,\"rgb(29,145,192)\"],[0.75,\"rgb(34,94,168)\"],[0.875,\"rgb(37,52,148)\"],[1.0,\"rgb(8,29,88)\"]],\"text\":[[1.0,0.0004,0.0135,0.0085,0.008,0.1477,-0.1477,0.1566,-0.1566,-0.0164,0.1732],[0.0004,1.0,-0.2411,0.0031,0.0508,0.2507,-0.2507,0.3376,-0.3376,-0.0792,0.1294],[0.0135,-0.2411,1.0,0.1445,0.1017,-0.177,0.177,-0.1817,0.1817,0.4398,0.2223],[0.0085,0.0031,0.1445,1.0,0.5383,-0.0231,0.0231,-0.005,0.005,-0.1345,0.1598],[0.008,0.0508,0.1017,0.5383,1.0,0.0136,-0.0136,0.0254,-0.0254,-0.0919,0.1201],[0.1477,0.2507,-0.177,-0.0231,0.0136,1.0,-1.0,0.5191,-0.5191,-0.132,0.0638],[-0.1477,-0.2507,0.177,0.0231,-0.0136,-1.0,1.0,-0.5191,0.5191,0.132,-0.0638],[0.1566,0.3376,-0.1817,-0.005,0.0254,0.5191,-0.5191,1.0,-1.0,-0.146,0.0766],[-0.1566,-0.3376,0.1817,0.005,-0.0254,-0.5191,0.5191,-1.0,1.0,0.146,-0.0766],[-0.0164,-0.0792,0.4398,-0.1345,-0.0919,-0.132,0.132,-0.146,0.146,1.0,0.1215],[0.1732,0.1294,0.2223,0.1598,0.1201,0.0638,-0.0638,0.0766,-0.0766,0.1215,1.0]],\"textfont\":{\"size\":12},\"texttemplate\":\"%{text}\",\"x\":[\"koi_disposition\",\"koi_fpflag_nt\",\"koi_fpflag_ss\",\"koi_fpflag_co\",\"koi_fpflag_ec\",\"koi_time0bk_err1\",\"koi_time0bk_err2\",\"koi_duration_err1\",\"koi_duration_err2\",\"koi_model_snr\",\"koi_steff_err1\"],\"y\":[\"koi_disposition\",\"koi_fpflag_nt\",\"koi_fpflag_ss\",\"koi_fpflag_co\",\"koi_fpflag_ec\",\"koi_time0bk_err1\",\"koi_time0bk_err2\",\"koi_duration_err1\",\"koi_duration_err2\",\"koi_model_snr\",\"koi_steff_err1\"],\"z\":[[1.0,0.0,0.014,0.009,0.008,0.148,-0.148,0.157,-0.157,-0.016,0.173],[0.0,1.0,-0.241,0.003,0.051,0.251,-0.251,0.338,-0.338,-0.079,0.129],[0.014,-0.241,1.0,0.145,0.102,-0.177,0.177,-0.182,0.182,0.44,0.222],[0.009,0.003,0.145,1.0,0.538,-0.023,0.023,-0.005,0.005,-0.134,0.16],[0.008,0.051,0.102,0.538,1.0,0.014,-0.014,0.025,-0.025,-0.092,0.12],[0.148,0.251,-0.177,-0.023,0.014,1.0,-1.0,0.519,-0.519,-0.132,0.064],[-0.148,-0.251,0.177,0.023,-0.014,-1.0,1.0,-0.519,0.519,0.132,-0.064],[0.157,0.338,-0.182,-0.005,0.025,0.519,-0.519,1.0,-1.0,-0.146,0.077],[-0.157,-0.338,0.182,0.005,-0.025,-0.519,0.519,-1.0,1.0,0.146,-0.077],[-0.016,-0.079,0.44,-0.134,-0.092,-0.132,0.132,-0.146,0.146,1.0,0.121],[0.173,0.129,0.222,0.16,0.12,0.064,-0.064,0.077,-0.077,0.121,1.0]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Top 10 Most Relevant Features Heatmap Correlation with the Target\",\"x\":0.5}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('2ab79df0-adf3-4aa6-9dbd-4714f93e4573');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure(data=go.Heatmap(z = rel_correlation.round(3).values.tolist(),\n",
    "                                x = rel_correlation.columns.to_list(),\n",
    "                                y = rel_correlation.index.to_list(),\n",
    "                                colorscale = 'ylgnbu',\n",
    "                                text = rel_correlation.round(4).values,\n",
    "                                texttemplate = \"%{text}\",\n",
    "                                textfont = {\"size\":12}))\n",
    "\n",
    "fig.update_layout(title_text='Top 10 Most Relevant Features Heatmap Correlation with the Target', title_x=0.5)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d1c640",
   "metadata": {},
   "outputs": [],
   "source": [
    "iplot(figfac.create_annotated_heatmap(rel_correlation.round(3).values, x=rel_correlation.columns.to_list(), \n",
    "                                  y=rel_correlation.index.to_list(), annotation_text=rel_correlation.round(4).values, colorscale= 'ylgnbu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c023e6",
   "metadata": {},
   "source": [
    "### Scaling in a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "efda1780",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('scaler', MinMaxScaler()),\n",
    "         ('logistic_regression', logreg)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d4080bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36514f62",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7638094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_space = np.logspace(-4, 4, 20)\n",
    "parameters = {'logistic_regression__C':c_space,\n",
    "              'logistic_regression__penalty':['l2', 'none'],\n",
    "              'logistic_regression__solver': ['lbfgs','newton-cg','sag'],\n",
    "             'logistic_regression__multi_class':['multinomial']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc3a990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "logreg_cv = GridSearchCV(pipeline, param_grid = parameters, verbose = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b31afc",
   "metadata": {},
   "source": [
    "### Running train_test_split but only with the relevant_features, selected by the RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c72b4318",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(relevant_features, target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b7ce10",
   "metadata": {},
   "source": [
    "### Fitting our model with all the possible parameters options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f72bdf7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "[CV 1/5] END logistic_regression__C=0.0001, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.508 total time=   0.0s\n",
      "[CV 2/5] END logistic_regression__C=0.0001, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.508 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=0.0001, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.507 total time=   0.0s\n",
      "[CV 4/5] END logistic_regression__C=0.0001, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.508 total time=   0.0s\n",
      "[CV 5/5] END logistic_regression__C=0.0001, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.508 total time=   0.0s\n",
      "[CV 1/5] END logistic_regression__C=0.0001, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.508 total time=   0.0s\n",
      "[CV 2/5] END logistic_regression__C=0.0001, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.508 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=0.0001, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.507 total time=   0.0s\n",
      "[CV 4/5] END logistic_regression__C=0.0001, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.508 total time=   0.0s\n",
      "[CV 5/5] END logistic_regression__C=0.0001, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.508 total time=   0.0s\n",
      "[CV 1/5] END logistic_regression__C=0.0001, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.508 total time=   0.0s\n",
      "[CV 2/5] END logistic_regression__C=0.0001, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.508 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=0.0001, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.507 total time=   0.0s\n",
      "[CV 4/5] END logistic_regression__C=0.0001, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.508 total time=   0.0s\n",
      "[CV 5/5] END logistic_regression__C=0.0001, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.508 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=0.0001, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.876 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=0.0001, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=0.0001, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.870 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=0.0001, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.845 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=0.0001, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.851 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=0.0001, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.876 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=0.0001, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=0.0001, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.870 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=0.0001, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=0.0001, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.851 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=0.0001, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=0.0001, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=0.0001, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.870 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=0.0001, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=0.0001, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.851 total time=   0.2s\n",
      "[CV 1/5] END logistic_regression__C=0.00026366508987303583, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.508 total time=   0.0s\n",
      "[CV 2/5] END logistic_regression__C=0.00026366508987303583, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.508 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=0.00026366508987303583, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.507 total time=   0.0s\n",
      "[CV 4/5] END logistic_regression__C=0.00026366508987303583, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.508 total time=   0.0s\n",
      "[CV 5/5] END logistic_regression__C=0.00026366508987303583, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.508 total time=   0.0s\n",
      "[CV 1/5] END logistic_regression__C=0.00026366508987303583, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.508 total time=   0.0s\n",
      "[CV 2/5] END logistic_regression__C=0.00026366508987303583, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.508 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=0.00026366508987303583, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.507 total time=   0.0s\n",
      "[CV 4/5] END logistic_regression__C=0.00026366508987303583, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.508 total time=   0.0s\n",
      "[CV 5/5] END logistic_regression__C=0.00026366508987303583, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.508 total time=   0.0s\n",
      "[CV 1/5] END logistic_regression__C=0.00026366508987303583, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.508 total time=   0.0s\n",
      "[CV 2/5] END logistic_regression__C=0.00026366508987303583, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.508 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=0.00026366508987303583, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.507 total time=   0.0s\n",
      "[CV 4/5] END logistic_regression__C=0.00026366508987303583, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.508 total time=   0.0s\n",
      "[CV 5/5] END logistic_regression__C=0.00026366508987303583, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.508 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=0.00026366508987303583, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=0.00026366508987303583, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.854 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=0.00026366508987303583, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.870 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=0.00026366508987303583, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.845 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=0.00026366508987303583, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.851 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=0.00026366508987303583, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.876 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=0.00026366508987303583, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=0.00026366508987303583, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.870 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=0.00026366508987303583, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=0.00026366508987303583, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.851 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=0.00026366508987303583, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=0.00026366508987303583, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=0.00026366508987303583, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.870 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=0.00026366508987303583, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=0.00026366508987303583, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.851 total time=   0.2s\n",
      "[CV 1/5] END logistic_regression__C=0.0006951927961775605, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.508 total time=   0.0s\n",
      "[CV 2/5] END logistic_regression__C=0.0006951927961775605, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.508 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=0.0006951927961775605, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.507 total time=   0.0s\n",
      "[CV 4/5] END logistic_regression__C=0.0006951927961775605, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.508 total time=   0.0s\n",
      "[CV 5/5] END logistic_regression__C=0.0006951927961775605, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.508 total time=   0.0s\n",
      "[CV 1/5] END logistic_regression__C=0.0006951927961775605, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.508 total time=   0.0s\n",
      "[CV 2/5] END logistic_regression__C=0.0006951927961775605, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.508 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=0.0006951927961775605, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.507 total time=   0.0s\n",
      "[CV 4/5] END logistic_regression__C=0.0006951927961775605, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.508 total time=   0.0s\n",
      "[CV 5/5] END logistic_regression__C=0.0006951927961775605, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.508 total time=   0.0s\n",
      "[CV 1/5] END logistic_regression__C=0.0006951927961775605, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.508 total time=   0.0s\n",
      "[CV 2/5] END logistic_regression__C=0.0006951927961775605, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.508 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=0.0006951927961775605, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.507 total time=   0.0s\n",
      "[CV 4/5] END logistic_regression__C=0.0006951927961775605, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.508 total time=   0.0s\n",
      "[CV 5/5] END logistic_regression__C=0.0006951927961775605, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.508 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=0.0006951927961775605, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=0.0006951927961775605, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.854 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=0.0006951927961775605, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.870 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=0.0006951927961775605, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.845 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=0.0006951927961775605, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.851 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=0.0006951927961775605, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.876 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=0.0006951927961775605, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=0.0006951927961775605, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.870 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=0.0006951927961775605, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=0.0006951927961775605, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.851 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=0.0006951927961775605, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=0.0006951927961775605, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=0.0006951927961775605, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.870 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=0.0006951927961775605, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=0.0006951927961775605, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.851 total time=   0.2s\n",
      "[CV 1/5] END logistic_regression__C=0.0018329807108324356, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.508 total time=   0.0s\n",
      "[CV 2/5] END logistic_regression__C=0.0018329807108324356, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.508 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=0.0018329807108324356, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.507 total time=   0.0s\n",
      "[CV 4/5] END logistic_regression__C=0.0018329807108324356, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.508 total time=   0.0s\n",
      "[CV 5/5] END logistic_regression__C=0.0018329807108324356, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.508 total time=   0.0s\n",
      "[CV 1/5] END logistic_regression__C=0.0018329807108324356, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.508 total time=   0.0s\n",
      "[CV 2/5] END logistic_regression__C=0.0018329807108324356, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.508 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=0.0018329807108324356, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.507 total time=   0.0s\n",
      "[CV 4/5] END logistic_regression__C=0.0018329807108324356, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.508 total time=   0.0s\n",
      "[CV 5/5] END logistic_regression__C=0.0018329807108324356, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.508 total time=   0.0s\n",
      "[CV 1/5] END logistic_regression__C=0.0018329807108324356, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.508 total time=   0.0s\n",
      "[CV 2/5] END logistic_regression__C=0.0018329807108324356, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.508 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=0.0018329807108324356, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.507 total time=   0.0s\n",
      "[CV 4/5] END logistic_regression__C=0.0018329807108324356, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.508 total time=   0.0s\n",
      "[CV 5/5] END logistic_regression__C=0.0018329807108324356, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.508 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=0.0018329807108324356, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=0.0018329807108324356, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.854 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=0.0018329807108324356, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.870 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=0.0018329807108324356, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.845 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=0.0018329807108324356, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.851 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=0.0018329807108324356, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.876 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=0.0018329807108324356, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=0.0018329807108324356, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.870 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=0.0018329807108324356, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=0.0018329807108324356, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.851 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=0.0018329807108324356, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=0.0018329807108324356, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=0.0018329807108324356, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.870 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=0.0018329807108324356, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=0.0018329807108324356, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.851 total time=   0.2s\n",
      "[CV 1/5] END logistic_regression__C=0.004832930238571752, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.777 total time=   0.0s\n",
      "[CV 2/5] END logistic_regression__C=0.004832930238571752, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.756 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=0.004832930238571752, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.761 total time=   0.0s\n",
      "[CV 4/5] END logistic_regression__C=0.004832930238571752, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.762 total time=   0.0s\n",
      "[CV 5/5] END logistic_regression__C=0.004832930238571752, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.770 total time=   0.0s\n",
      "[CV 1/5] END logistic_regression__C=0.004832930238571752, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.777 total time=   0.0s\n",
      "[CV 2/5] END logistic_regression__C=0.004832930238571752, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.756 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=0.004832930238571752, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.761 total time=   0.0s\n",
      "[CV 4/5] END logistic_regression__C=0.004832930238571752, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.762 total time=   0.0s\n",
      "[CV 5/5] END logistic_regression__C=0.004832930238571752, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.770 total time=   0.0s\n",
      "[CV 1/5] END logistic_regression__C=0.004832930238571752, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.777 total time=   0.0s\n",
      "[CV 2/5] END logistic_regression__C=0.004832930238571752, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.756 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=0.004832930238571752, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.761 total time=   0.0s\n",
      "[CV 4/5] END logistic_regression__C=0.004832930238571752, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.762 total time=   0.0s\n",
      "[CV 5/5] END logistic_regression__C=0.004832930238571752, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.770 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=0.004832930238571752, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=0.004832930238571752, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.854 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=0.004832930238571752, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.870 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=0.004832930238571752, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.845 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=0.004832930238571752, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.851 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=0.004832930238571752, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.876 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=0.004832930238571752, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=0.004832930238571752, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.870 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=0.004832930238571752, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=0.004832930238571752, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.851 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=0.004832930238571752, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=0.004832930238571752, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=0.004832930238571752, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.870 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=0.004832930238571752, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=0.004832930238571752, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.851 total time=   0.2s\n",
      "[CV 1/5] END logistic_regression__C=0.012742749857031334, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.826 total time=   0.0s\n",
      "[CV 2/5] END logistic_regression__C=0.012742749857031334, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.790 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=0.012742749857031334, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.804 total time=   0.0s\n",
      "[CV 4/5] END logistic_regression__C=0.012742749857031334, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.808 total time=   0.0s\n",
      "[CV 5/5] END logistic_regression__C=0.012742749857031334, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.799 total time=   0.0s\n",
      "[CV 1/5] END logistic_regression__C=0.012742749857031334, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.826 total time=   0.0s\n",
      "[CV 2/5] END logistic_regression__C=0.012742749857031334, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.790 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=0.012742749857031334, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.804 total time=   0.0s\n",
      "[CV 4/5] END logistic_regression__C=0.012742749857031334, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.808 total time=   0.0s\n",
      "[CV 5/5] END logistic_regression__C=0.012742749857031334, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.799 total time=   0.0s\n",
      "[CV 1/5] END logistic_regression__C=0.012742749857031334, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.826 total time=   0.0s\n",
      "[CV 2/5] END logistic_regression__C=0.012742749857031334, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.790 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=0.012742749857031334, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.804 total time=   0.0s\n",
      "[CV 4/5] END logistic_regression__C=0.012742749857031334, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.808 total time=   0.0s\n",
      "[CV 5/5] END logistic_regression__C=0.012742749857031334, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.799 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=0.012742749857031334, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=0.012742749857031334, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.854 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=0.012742749857031334, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.870 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=0.012742749857031334, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.845 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=0.012742749857031334, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.851 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=0.012742749857031334, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.876 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=0.012742749857031334, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=0.012742749857031334, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.870 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=0.012742749857031334, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=0.012742749857031334, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.851 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=0.012742749857031334, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=0.012742749857031334, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=0.012742749857031334, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.870 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=0.012742749857031334, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=0.012742749857031334, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.851 total time=   0.2s\n",
      "[CV 1/5] END logistic_regression__C=0.03359818286283781, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.853 total time=   0.0s\n",
      "[CV 2/5] END logistic_regression__C=0.03359818286283781, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=0.03359818286283781, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.841 total time=   0.0s\n",
      "[CV 4/5] END logistic_regression__C=0.03359818286283781, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.825 total time=   0.0s\n",
      "[CV 5/5] END logistic_regression__C=0.03359818286283781, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.830 total time=   0.0s\n",
      "[CV 1/5] END logistic_regression__C=0.03359818286283781, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.853 total time=   0.0s\n",
      "[CV 2/5] END logistic_regression__C=0.03359818286283781, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=0.03359818286283781, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.841 total time=   0.0s\n",
      "[CV 4/5] END logistic_regression__C=0.03359818286283781, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.825 total time=   0.0s\n",
      "[CV 5/5] END logistic_regression__C=0.03359818286283781, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.830 total time=   0.0s\n",
      "[CV 1/5] END logistic_regression__C=0.03359818286283781, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.853 total time=   0.0s\n",
      "[CV 2/5] END logistic_regression__C=0.03359818286283781, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.834 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=0.03359818286283781, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.840 total time=   0.0s\n",
      "[CV 4/5] END logistic_regression__C=0.03359818286283781, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.826 total time=   0.0s\n",
      "[CV 5/5] END logistic_regression__C=0.03359818286283781, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.831 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=0.03359818286283781, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=0.03359818286283781, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.854 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=0.03359818286283781, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.870 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=0.03359818286283781, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.845 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=0.03359818286283781, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.851 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=0.03359818286283781, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.876 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=0.03359818286283781, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=0.03359818286283781, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.870 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=0.03359818286283781, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=0.03359818286283781, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.851 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=0.03359818286283781, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=0.03359818286283781, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=0.03359818286283781, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.870 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=0.03359818286283781, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=0.03359818286283781, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.851 total time=   0.2s\n",
      "[CV 1/5] END logistic_regression__C=0.08858667904100823, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.850 total time=   0.0s\n",
      "[CV 2/5] END logistic_regression__C=0.08858667904100823, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.828 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=0.08858667904100823, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.850 total time=   0.0s\n",
      "[CV 4/5] END logistic_regression__C=0.08858667904100823, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.836 total time=   0.0s\n",
      "[CV 5/5] END logistic_regression__C=0.08858667904100823, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.831 total time=   0.0s\n",
      "[CV 1/5] END logistic_regression__C=0.08858667904100823, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.850 total time=   0.0s\n",
      "[CV 2/5] END logistic_regression__C=0.08858667904100823, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.828 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=0.08858667904100823, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.850 total time=   0.0s\n",
      "[CV 4/5] END logistic_regression__C=0.08858667904100823, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 5/5] END logistic_regression__C=0.08858667904100823, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.831 total time=   0.0s\n",
      "[CV 1/5] END logistic_regression__C=0.08858667904100823, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.850 total time=   0.0s\n",
      "[CV 2/5] END logistic_regression__C=0.08858667904100823, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.828 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=0.08858667904100823, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.848 total time=   0.0s\n",
      "[CV 4/5] END logistic_regression__C=0.08858667904100823, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.836 total time=   0.0s\n",
      "[CV 5/5] END logistic_regression__C=0.08858667904100823, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=0.08858667904100823, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=0.08858667904100823, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.854 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=0.08858667904100823, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.870 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=0.08858667904100823, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.845 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=0.08858667904100823, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.851 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=0.08858667904100823, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.876 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=0.08858667904100823, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=0.08858667904100823, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.870 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=0.08858667904100823, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=0.08858667904100823, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.851 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=0.08858667904100823, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.876 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=0.08858667904100823, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=0.08858667904100823, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.870 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=0.08858667904100823, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=0.08858667904100823, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.851 total time=   0.2s\n",
      "[CV 1/5] END logistic_regression__C=0.23357214690901212, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.856 total time=   0.0s\n",
      "[CV 2/5] END logistic_regression__C=0.23357214690901212, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.832 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=0.23357214690901212, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.851 total time=   0.0s\n",
      "[CV 4/5] END logistic_regression__C=0.23357214690901212, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.834 total time=   0.0s\n",
      "[CV 5/5] END logistic_regression__C=0.23357214690901212, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END logistic_regression__C=0.23357214690901212, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.856 total time=   0.0s\n",
      "[CV 2/5] END logistic_regression__C=0.23357214690901212, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.832 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=0.23357214690901212, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.851 total time=   0.0s\n",
      "[CV 4/5] END logistic_regression__C=0.23357214690901212, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.834 total time=   0.0s\n",
      "[CV 5/5] END logistic_regression__C=0.23357214690901212, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END logistic_regression__C=0.23357214690901212, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.856 total time=   0.0s\n",
      "[CV 2/5] END logistic_regression__C=0.23357214690901212, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.832 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=0.23357214690901212, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.851 total time=   0.0s\n",
      "[CV 4/5] END logistic_regression__C=0.23357214690901212, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.834 total time=   0.0s\n",
      "[CV 5/5] END logistic_regression__C=0.23357214690901212, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.833 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=0.23357214690901212, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=0.23357214690901212, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.854 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=0.23357214690901212, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.870 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=0.23357214690901212, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.845 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=0.23357214690901212, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.851 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=0.23357214690901212, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.876 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=0.23357214690901212, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=0.23357214690901212, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.870 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=0.23357214690901212, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=0.23357214690901212, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.851 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=0.23357214690901212, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=0.23357214690901212, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=0.23357214690901212, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.870 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=0.23357214690901212, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=0.23357214690901212, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.851 total time=   0.2s\n",
      "[CV 1/5] END logistic_regression__C=0.615848211066026, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.867 total time=   0.1s\n",
      "[CV 2/5] END logistic_regression__C=0.615848211066026, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.839 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=0.615848211066026, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.855 total time=   0.1s\n",
      "[CV 4/5] END logistic_regression__C=0.615848211066026, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.836 total time=   0.1s\n",
      "[CV 5/5] END logistic_regression__C=0.615848211066026, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.835 total time=   0.0s\n",
      "[CV 1/5] END logistic_regression__C=0.615848211066026, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.867 total time=   0.0s\n",
      "[CV 2/5] END logistic_regression__C=0.615848211066026, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.839 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=0.615848211066026, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.855 total time=   0.0s\n",
      "[CV 4/5] END logistic_regression__C=0.615848211066026, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 5/5] END logistic_regression__C=0.615848211066026, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.835 total time=   0.0s\n",
      "[CV 1/5] END logistic_regression__C=0.615848211066026, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.867 total time=   0.0s\n",
      "[CV 2/5] END logistic_regression__C=0.615848211066026, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=0.615848211066026, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.855 total time=   0.0s\n",
      "[CV 4/5] END logistic_regression__C=0.615848211066026, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.836 total time=   0.0s\n",
      "[CV 5/5] END logistic_regression__C=0.615848211066026, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.835 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=0.615848211066026, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=0.615848211066026, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.854 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=0.615848211066026, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.870 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=0.615848211066026, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.845 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=0.615848211066026, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.851 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=0.615848211066026, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.876 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=0.615848211066026, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=0.615848211066026, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.870 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=0.615848211066026, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=0.615848211066026, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.851 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=0.615848211066026, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=0.615848211066026, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=0.615848211066026, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.870 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=0.615848211066026, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=0.615848211066026, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.851 total time=   0.2s\n",
      "[CV 1/5] END logistic_regression__C=1.623776739188721, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.874 total time=   0.2s\n",
      "[CV 2/5] END logistic_regression__C=1.623776739188721, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.844 total time=   0.2s\n",
      "[CV 3/5] END logistic_regression__C=1.623776739188721, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.860 total time=   0.2s\n",
      "[CV 4/5] END logistic_regression__C=1.623776739188721, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.848 total time=   0.1s\n",
      "[CV 5/5] END logistic_regression__C=1.623776739188721, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.849 total time=   0.2s\n",
      "[CV 1/5] END logistic_regression__C=1.623776739188721, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.874 total time=   0.0s\n",
      "[CV 2/5] END logistic_regression__C=1.623776739188721, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.844 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=1.623776739188721, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.860 total time=   0.0s\n",
      "[CV 4/5] END logistic_regression__C=1.623776739188721, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.848 total time=   0.1s\n",
      "[CV 5/5] END logistic_regression__C=1.623776739188721, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.849 total time=   0.0s\n",
      "[CV 1/5] END logistic_regression__C=1.623776739188721, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.874 total time=   0.0s\n",
      "[CV 2/5] END logistic_regression__C=1.623776739188721, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.844 total time=   0.0s\n",
      "[CV 3/5] END logistic_regression__C=1.623776739188721, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.860 total time=   0.0s\n",
      "[CV 4/5] END logistic_regression__C=1.623776739188721, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.848 total time=   0.0s\n",
      "[CV 5/5] END logistic_regression__C=1.623776739188721, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.849 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=1.623776739188721, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=1.623776739188721, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.854 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=1.623776739188721, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.870 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=1.623776739188721, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.845 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=1.623776739188721, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.851 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=1.623776739188721, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.876 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=1.623776739188721, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=1.623776739188721, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.870 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=1.623776739188721, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=1.623776739188721, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.851 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=1.623776739188721, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=1.623776739188721, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=1.623776739188721, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.870 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=1.623776739188721, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=1.623776739188721, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.851 total time=   0.2s\n",
      "[CV 1/5] END logistic_regression__C=4.281332398719396, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.875 total time=   0.2s\n",
      "[CV 2/5] END logistic_regression__C=4.281332398719396, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.846 total time=   0.3s\n",
      "[CV 3/5] END logistic_regression__C=4.281332398719396, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.866 total time=   0.2s\n",
      "[CV 4/5] END logistic_regression__C=4.281332398719396, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.846 total time=   0.3s\n",
      "[CV 5/5] END logistic_regression__C=4.281332398719396, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.851 total time=   0.3s\n",
      "[CV 1/5] END logistic_regression__C=4.281332398719396, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.875 total time=   0.1s\n",
      "[CV 2/5] END logistic_regression__C=4.281332398719396, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.846 total time=   0.1s\n",
      "[CV 3/5] END logistic_regression__C=4.281332398719396, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.866 total time=   0.1s\n",
      "[CV 4/5] END logistic_regression__C=4.281332398719396, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.846 total time=   0.1s\n",
      "[CV 5/5] END logistic_regression__C=4.281332398719396, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.851 total time=   0.1s\n",
      "[CV 1/5] END logistic_regression__C=4.281332398719396, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.875 total time=   0.1s\n",
      "[CV 2/5] END logistic_regression__C=4.281332398719396, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.846 total time=   0.1s\n",
      "[CV 3/5] END logistic_regression__C=4.281332398719396, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.866 total time=   0.1s\n",
      "[CV 4/5] END logistic_regression__C=4.281332398719396, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.846 total time=   0.1s\n",
      "[CV 5/5] END logistic_regression__C=4.281332398719396, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.851 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=4.281332398719396, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=4.281332398719396, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.854 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=4.281332398719396, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.870 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=4.281332398719396, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.845 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=4.281332398719396, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.851 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=4.281332398719396, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.876 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=4.281332398719396, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=4.281332398719396, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.870 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=4.281332398719396, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=4.281332398719396, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.851 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=4.281332398719396, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=4.281332398719396, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=4.281332398719396, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.870 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=4.281332398719396, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=4.281332398719396, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.851 total time=   0.2s\n",
      "[CV 1/5] END logistic_regression__C=11.288378916846883, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.875 total time=   0.4s\n",
      "[CV 2/5] END logistic_regression__C=11.288378916846883, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.855 total time=   0.4s\n",
      "[CV 3/5] END logistic_regression__C=11.288378916846883, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.868 total time=   0.4s\n",
      "[CV 4/5] END logistic_regression__C=11.288378916846883, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.845 total time=   0.4s\n",
      "[CV 5/5] END logistic_regression__C=11.288378916846883, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.852 total time=   0.4s\n",
      "[CV 1/5] END logistic_regression__C=11.288378916846883, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.875 total time=   0.1s\n",
      "[CV 2/5] END logistic_regression__C=11.288378916846883, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.855 total time=   0.1s\n",
      "[CV 3/5] END logistic_regression__C=11.288378916846883, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.868 total time=   0.1s\n",
      "[CV 4/5] END logistic_regression__C=11.288378916846883, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.845 total time=   0.1s\n",
      "[CV 5/5] END logistic_regression__C=11.288378916846883, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.852 total time=   0.1s\n",
      "[CV 1/5] END logistic_regression__C=11.288378916846883, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.875 total time=   0.2s\n",
      "[CV 2/5] END logistic_regression__C=11.288378916846883, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.855 total time=   0.2s\n",
      "[CV 3/5] END logistic_regression__C=11.288378916846883, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.868 total time=   0.2s\n",
      "[CV 4/5] END logistic_regression__C=11.288378916846883, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.845 total time=   0.2s\n",
      "[CV 5/5] END logistic_regression__C=11.288378916846883, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.852 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=11.288378916846883, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=11.288378916846883, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.854 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=11.288378916846883, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.870 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=11.288378916846883, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.845 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=11.288378916846883, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.851 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=11.288378916846883, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.876 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=11.288378916846883, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=11.288378916846883, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.870 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=11.288378916846883, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=11.288378916846883, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.851 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=11.288378916846883, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=11.288378916846883, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=11.288378916846883, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.870 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=11.288378916846883, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=11.288378916846883, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.851 total time=   0.2s\n",
      "[CV 1/5] END logistic_regression__C=29.763514416313132, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.877 total time=   0.5s\n",
      "[CV 2/5] END logistic_regression__C=29.763514416313132, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.855 total time=   0.4s\n",
      "[CV 3/5] END logistic_regression__C=29.763514416313132, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.867 total time=   0.5s\n",
      "[CV 4/5] END logistic_regression__C=29.763514416313132, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.845 total time=   0.4s\n",
      "[CV 5/5] END logistic_regression__C=29.763514416313132, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.849 total time=   0.5s\n",
      "[CV 1/5] END logistic_regression__C=29.763514416313132, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.877 total time=   0.1s\n",
      "[CV 2/5] END logistic_regression__C=29.763514416313132, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.855 total time=   0.1s\n",
      "[CV 3/5] END logistic_regression__C=29.763514416313132, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.867 total time=   0.1s\n",
      "[CV 4/5] END logistic_regression__C=29.763514416313132, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.845 total time=   0.1s\n",
      "[CV 5/5] END logistic_regression__C=29.763514416313132, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.849 total time=   0.1s\n",
      "[CV 1/5] END logistic_regression__C=29.763514416313132, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.877 total time=   0.5s\n",
      "[CV 2/5] END logistic_regression__C=29.763514416313132, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.855 total time=   0.5s\n",
      "[CV 3/5] END logistic_regression__C=29.763514416313132, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.867 total time=   0.5s\n",
      "[CV 4/5] END logistic_regression__C=29.763514416313132, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.845 total time=   0.5s\n",
      "[CV 5/5] END logistic_regression__C=29.763514416313132, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.849 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=29.763514416313132, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=29.763514416313132, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.854 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=29.763514416313132, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.870 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=29.763514416313132, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.845 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=29.763514416313132, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.851 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=29.763514416313132, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.876 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=29.763514416313132, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=29.763514416313132, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.870 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=29.763514416313132, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=29.763514416313132, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.851 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=29.763514416313132, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=29.763514416313132, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=29.763514416313132, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.870 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=29.763514416313132, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=29.763514416313132, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.851 total time=   0.2s\n",
      "[CV 1/5] END logistic_regression__C=78.47599703514607, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.875 total time=   0.6s\n",
      "[CV 2/5] END logistic_regression__C=78.47599703514607, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.856 total time=   0.7s\n",
      "[CV 3/5] END logistic_regression__C=78.47599703514607, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.869 total time=   0.6s\n",
      "[CV 4/5] END logistic_regression__C=78.47599703514607, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.848 total time=   0.7s\n",
      "[CV 5/5] END logistic_regression__C=78.47599703514607, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.850 total time=   0.7s\n",
      "[CV 1/5] END logistic_regression__C=78.47599703514607, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.875 total time=   0.1s\n",
      "[CV 2/5] END logistic_regression__C=78.47599703514607, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.856 total time=   0.1s\n",
      "[CV 3/5] END logistic_regression__C=78.47599703514607, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.869 total time=   0.1s\n",
      "[CV 4/5] END logistic_regression__C=78.47599703514607, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.848 total time=   0.1s\n",
      "[CV 5/5] END logistic_regression__C=78.47599703514607, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.850 total time=   0.2s\n",
      "[CV 1/5] END logistic_regression__C=78.47599703514607, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.874 total time=   0.9s\n",
      "[CV 2/5] END logistic_regression__C=78.47599703514607, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.856 total time=   0.9s\n",
      "[CV 3/5] END logistic_regression__C=78.47599703514607, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.869 total time=   0.9s\n",
      "[CV 4/5] END logistic_regression__C=78.47599703514607, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.848 total time=   0.9s\n",
      "[CV 5/5] END logistic_regression__C=78.47599703514607, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.850 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=78.47599703514607, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=78.47599703514607, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.854 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=78.47599703514607, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.870 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=78.47599703514607, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.845 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=78.47599703514607, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.851 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=78.47599703514607, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.876 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=78.47599703514607, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=78.47599703514607, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.870 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=78.47599703514607, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=78.47599703514607, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.851 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=78.47599703514607, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=78.47599703514607, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=78.47599703514607, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.870 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=78.47599703514607, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=78.47599703514607, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.851 total time=   0.2s\n",
      "[CV 1/5] END logistic_regression__C=206.913808111479, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.876 total time=   0.9s\n",
      "[CV 2/5] END logistic_regression__C=206.913808111479, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.854 total time=   1.0s\n",
      "[CV 3/5] END logistic_regression__C=206.913808111479, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.869 total time=   0.7s\n",
      "[CV 4/5] END logistic_regression__C=206.913808111479, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.844 total time=   1.0s\n",
      "[CV 5/5] END logistic_regression__C=206.913808111479, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.850 total time=   0.9s\n",
      "[CV 1/5] END logistic_regression__C=206.913808111479, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.876 total time=   0.1s\n",
      "[CV 2/5] END logistic_regression__C=206.913808111479, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.854 total time=   0.2s\n",
      "[CV 3/5] END logistic_regression__C=206.913808111479, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.869 total time=   0.2s\n",
      "[CV 4/5] END logistic_regression__C=206.913808111479, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.844 total time=   0.1s\n",
      "[CV 5/5] END logistic_regression__C=206.913808111479, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.850 total time=   0.1s\n",
      "[CV 1/5] END logistic_regression__C=206.913808111479, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.876 total time=   1.1s\n",
      "[CV 2/5] END logistic_regression__C=206.913808111479, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.854 total time=   1.1s\n",
      "[CV 3/5] END logistic_regression__C=206.913808111479, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.868 total time=   1.2s\n",
      "[CV 4/5] END logistic_regression__C=206.913808111479, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.844 total time=   1.2s\n",
      "[CV 5/5] END logistic_regression__C=206.913808111479, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.850 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=206.913808111479, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=206.913808111479, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.854 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=206.913808111479, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.870 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=206.913808111479, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.845 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=206.913808111479, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.851 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=206.913808111479, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.876 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=206.913808111479, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=206.913808111479, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.870 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=206.913808111479, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=206.913808111479, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.851 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=206.913808111479, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=206.913808111479, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=206.913808111479, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.870 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=206.913808111479, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=206.913808111479, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.851 total time=   0.2s\n",
      "[CV 1/5] END logistic_regression__C=545.5594781168514, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.876 total time=   1.1s\n",
      "[CV 2/5] END logistic_regression__C=545.5594781168514, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.853 total time=   1.2s\n",
      "[CV 3/5] END logistic_regression__C=545.5594781168514, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.870 total time=   1.2s\n",
      "[CV 4/5] END logistic_regression__C=545.5594781168514, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.843 total time=   1.3s\n",
      "[CV 5/5] END logistic_regression__C=545.5594781168514, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.851 total time=   1.3s\n",
      "[CV 1/5] END logistic_regression__C=545.5594781168514, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.876 total time=   0.1s\n",
      "[CV 2/5] END logistic_regression__C=545.5594781168514, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.853 total time=   0.2s\n",
      "[CV 3/5] END logistic_regression__C=545.5594781168514, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.870 total time=   0.2s\n",
      "[CV 4/5] END logistic_regression__C=545.5594781168514, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.843 total time=   0.1s\n",
      "[CV 5/5] END logistic_regression__C=545.5594781168514, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.851 total time=   0.2s\n",
      "[CV 1/5] END logistic_regression__C=545.5594781168514, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.876 total time=   1.3s\n",
      "[CV 2/5] END logistic_regression__C=545.5594781168514, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.853 total time=   1.1s\n",
      "[CV 3/5] END logistic_regression__C=545.5594781168514, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.870 total time=   0.8s\n",
      "[CV 4/5] END logistic_regression__C=545.5594781168514, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.843 total time=   0.7s\n",
      "[CV 5/5] END logistic_regression__C=545.5594781168514, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.851 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=545.5594781168514, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=545.5594781168514, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.854 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=545.5594781168514, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.870 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=545.5594781168514, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.845 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=545.5594781168514, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.851 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=545.5594781168514, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.876 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=545.5594781168514, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=545.5594781168514, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.870 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=545.5594781168514, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=545.5594781168514, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.851 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=545.5594781168514, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=545.5594781168514, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=545.5594781168514, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.870 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=545.5594781168514, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=545.5594781168514, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.851 total time=   0.2s\n",
      "[CV 1/5] END logistic_regression__C=1438.44988828766, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.876 total time=   1.1s\n",
      "[CV 2/5] END logistic_regression__C=1438.44988828766, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.853 total time=   1.0s\n",
      "[CV 3/5] END logistic_regression__C=1438.44988828766, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.870 total time=   0.9s\n",
      "[CV 4/5] END logistic_regression__C=1438.44988828766, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.844 total time=   0.8s\n",
      "[CV 5/5] END logistic_regression__C=1438.44988828766, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.851 total time=   1.0s\n",
      "[CV 1/5] END logistic_regression__C=1438.44988828766, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.876 total time=   0.1s\n",
      "[CV 2/5] END logistic_regression__C=1438.44988828766, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.854 total time=   0.2s\n",
      "[CV 3/5] END logistic_regression__C=1438.44988828766, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.870 total time=   0.2s\n",
      "[CV 4/5] END logistic_regression__C=1438.44988828766, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.844 total time=   0.2s\n",
      "[CV 5/5] END logistic_regression__C=1438.44988828766, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.851 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=1438.44988828766, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.876 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=1438.44988828766, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.854 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=1438.44988828766, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.870 total time=   1.5s\n",
      "[CV 4/5] END logistic_regression__C=1438.44988828766, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.844 total time=   0.7s\n",
      "[CV 5/5] END logistic_regression__C=1438.44988828766, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.851 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=1438.44988828766, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=1438.44988828766, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.854 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=1438.44988828766, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.870 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=1438.44988828766, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.845 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=1438.44988828766, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.851 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=1438.44988828766, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.876 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=1438.44988828766, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=1438.44988828766, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.870 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=1438.44988828766, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=1438.44988828766, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.851 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=1438.44988828766, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=1438.44988828766, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=1438.44988828766, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.870 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=1438.44988828766, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=1438.44988828766, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.851 total time=   0.2s\n",
      "[CV 1/5] END logistic_regression__C=3792.690190732246, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.876 total time=   0.5s\n",
      "[CV 2/5] END logistic_regression__C=3792.690190732246, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.854 total time=   1.0s\n",
      "[CV 3/5] END logistic_regression__C=3792.690190732246, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.870 total time=   0.4s\n",
      "[CV 4/5] END logistic_regression__C=3792.690190732246, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.845 total time=   0.4s\n",
      "[CV 5/5] END logistic_regression__C=3792.690190732246, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.851 total time=   0.4s\n",
      "[CV 1/5] END logistic_regression__C=3792.690190732246, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.876 total time=   0.2s\n",
      "[CV 2/5] END logistic_regression__C=3792.690190732246, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.854 total time=   0.2s\n",
      "[CV 3/5] END logistic_regression__C=3792.690190732246, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.870 total time=   0.2s\n",
      "[CV 4/5] END logistic_regression__C=3792.690190732246, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.845 total time=   0.2s\n",
      "[CV 5/5] END logistic_regression__C=3792.690190732246, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.851 total time=   0.2s\n",
      "[CV 1/5] END logistic_regression__C=3792.690190732246, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.876 total time=   0.5s\n",
      "[CV 2/5] END logistic_regression__C=3792.690190732246, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.854 total time=   0.2s\n",
      "[CV 3/5] END logistic_regression__C=3792.690190732246, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.870 total time=   0.3s\n",
      "[CV 4/5] END logistic_regression__C=3792.690190732246, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.845 total time=   0.2s\n",
      "[CV 5/5] END logistic_regression__C=3792.690190732246, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.851 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=3792.690190732246, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=3792.690190732246, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.854 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=3792.690190732246, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.870 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=3792.690190732246, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.845 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=3792.690190732246, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.851 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=3792.690190732246, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.876 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=3792.690190732246, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=3792.690190732246, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.870 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=3792.690190732246, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=3792.690190732246, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.851 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=3792.690190732246, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=3792.690190732246, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=3792.690190732246, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.870 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=3792.690190732246, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=3792.690190732246, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.851 total time=   0.2s\n",
      "[CV 1/5] END logistic_regression__C=10000.0, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.876 total time=   0.4s\n",
      "[CV 2/5] END logistic_regression__C=10000.0, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.854 total time=   0.4s\n",
      "[CV 3/5] END logistic_regression__C=10000.0, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.870 total time=   0.4s\n",
      "[CV 4/5] END logistic_regression__C=10000.0, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.845 total time=   0.3s\n",
      "[CV 5/5] END logistic_regression__C=10000.0, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=lbfgs;, score=0.851 total time=   0.4s\n",
      "[CV 1/5] END logistic_regression__C=10000.0, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.876 total time=   0.2s\n",
      "[CV 2/5] END logistic_regression__C=10000.0, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.854 total time=   0.2s\n",
      "[CV 3/5] END logistic_regression__C=10000.0, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.870 total time=   0.2s\n",
      "[CV 4/5] END logistic_regression__C=10000.0, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.845 total time=   0.2s\n",
      "[CV 5/5] END logistic_regression__C=10000.0, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=newton-cg;, score=0.851 total time=   0.2s\n",
      "[CV 1/5] END logistic_regression__C=10000.0, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.876 total time=   0.5s\n",
      "[CV 2/5] END logistic_regression__C=10000.0, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.854 total time=   0.2s\n",
      "[CV 3/5] END logistic_regression__C=10000.0, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.870 total time=   0.3s\n",
      "[CV 4/5] END logistic_regression__C=10000.0, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.845 total time=   0.2s\n",
      "[CV 5/5] END logistic_regression__C=10000.0, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=l2, logistic_regression__solver=sag;, score=0.851 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=10000.0, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=10000.0, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.854 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=10000.0, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.870 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=10000.0, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.845 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=10000.0, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=lbfgs;, score=0.851 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=10000.0, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.876 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=10000.0, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=10000.0, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.870 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=10000.0, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=10000.0, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=newton-cg;, score=0.851 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logistic_regression__C=10000.0, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.876 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logistic_regression__C=10000.0, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.854 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logistic_regression__C=10000.0, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.870 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END logistic_regression__C=10000.0, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.845 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raulm\\anaconda3\\envs\\pythondata\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END logistic_regression__C=10000.0, logistic_regression__max_iter=1000, logistic_regression__multi_class=multinomial, logistic_regression__penalty=none, logistic_regression__solver=sag;, score=0.851 total time=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                                       ('logistic_regression',\n",
       "                                        LogisticRegression(max_iter=1000))]),\n",
       "             param_grid={'logistic_regression__C': array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n",
       "                         'logistic_regression__max_iter': [1000],\n",
       "                         'logistic_regression__multi_class': ['multinomial'],\n",
       "                         'logistic_regression__penalty': ['l2', 'none'],\n",
       "                         'logistic_regression__solver': ['lbfgs', 'newton-cg',\n",
       "                                                         'sag']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a480f6",
   "metadata": {},
   "source": [
    "### Collecting the predictions for the X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5d0ea665",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = logreg_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99e460b",
   "metadata": {},
   "source": [
    "### Model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a8a2414b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================\n",
      "Models Accuracy\n",
      "=======================================\n",
      "Accuracy: 85.55767397521448%\n",
      "---------------------------------------\n",
      "Classification Report\n",
      "=======================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.80      0.76       574\n",
      "           1       0.98      1.00      0.99      1020\n",
      "           2       0.76      0.62      0.68       504\n",
      "\n",
      "    accuracy                           0.86      2098\n",
      "   macro avg       0.82      0.81      0.81      2098\n",
      "weighted avg       0.86      0.86      0.85      2098\n",
      "\n",
      "---------------------------------------\n",
      "Best Parameters\n",
      "=======================================\n",
      "Tuned Model Parameters: {'logistic_regression__C': 78.47599703514607, 'logistic_regression__max_iter': 1000, 'logistic_regression__multi_class': 'multinomial', 'logistic_regression__penalty': 'l2', 'logistic_regression__solver': 'lbfgs'}\n",
      "---------------------------------------\n",
      "Confusion Matrix\n",
      "=======================================\n",
      "[[ 462   12  100]\n",
      " [   0 1018    2]\n",
      " [ 182    7  315]]\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(\"=======================================\")\n",
    "print(\"Models Accuracy\")\n",
    "print(\"=======================================\")\n",
    "print(\"Accuracy: {}%\".format((logreg_cv.score(X_test, y_test))*100))\n",
    "print(\"---------------------------------------\")\n",
    "print(\"Classification Report\")\n",
    "print(\"=======================================\")\n",
    "print(classification_report(y_test, predict))\n",
    "print(\"---------------------------------------\")\n",
    "print(\"Best Parameters\")\n",
    "print(\"=======================================\")\n",
    "print(\"Tuned Model Parameters: {}\".format(logreg_cv.best_params_))\n",
    "print(\"---------------------------------------\")\n",
    "print(\"Confusion Matrix\")\n",
    "print(\"=======================================\")\n",
    "print(confusion_matrix(y_test, predict))\n",
    "print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1615a13d",
   "metadata": {},
   "source": [
    "### Prediction vs Actual DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80e17842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2098 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Prediction          Actual\n",
       "0     FALSE POSITIVE  FALSE POSITIVE\n",
       "1          CANDIDATE       CANDIDATE\n",
       "2     FALSE POSITIVE  FALSE POSITIVE\n",
       "3     FALSE POSITIVE  FALSE POSITIVE\n",
       "4     FALSE POSITIVE  FALSE POSITIVE\n",
       "...              ...             ...\n",
       "2093  FALSE POSITIVE  FALSE POSITIVE\n",
       "2094       CANDIDATE       CONFIRMED\n",
       "2095       CONFIRMED       CANDIDATE\n",
       "2096       CONFIRMED       CONFIRMED\n",
       "2097       CANDIDATE       CONFIRMED\n",
       "\n",
       "[2098 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_df = pd.DataFrame({'Prediction':predict, 'Actual':y_test}).reset_index(drop=True)\n",
    "predictor_df[['Prediction', 'Actual']] = predictor_df[['Prediction', 'Actual']].replace({0: 'CONFIRMED', 1: 'FALSE POSITIVE', 2 : 'CANDIDATE'})\n",
    "predictor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841d890e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
